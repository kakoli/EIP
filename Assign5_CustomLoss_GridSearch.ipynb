{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign5_CustomLoss_GridSearch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9aAeoiGWWrY",
        "colab_type": "text"
      },
      "source": [
        "####  **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "outputId": "ade5cdc4-6093-4e2c-e2b7-538fb9ff7ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "dir=\"/content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bugf5EB4WaA2",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets\n",
        "Plotting a sample image from the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "dca6e24c-a953-45e0-e356-df793e398551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print (x_train.shape)\n",
        "\n",
        "plt.imshow(x_train[1], cmap='gray')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fae68f435c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADjBJREFUeJzt3X+MVfWZx/HPoy1EpRi1WRxFl26D\nTRqjg4zEP8jKumvjIgk0RoUYh6bNDn+UxJqNqdpRSdaNjVE2aiKRKimsLFBFAzbr0i5jtE1M44is\nP7eVbagdHBkRI0NMZIVn/7iHzaBzv+dy77n3nJnn/Uomc+957rnn8Tofzj33e+75mrsLQDynlN0A\ngHIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQX2lkxszM04nBNrM3a2Rx7W05zeza8zs92a2\nx8xub+W5AHSWNXtuv5mdKukPkq6WNCTpFUnL3P3txDrs+YE268Sef56kPe7+R3c/ImmzpMUtPB+A\nDmol/OdL+vOY+0PZshOYWZ+ZDZrZYAvbAlCwtn/g5+5rJa2VeNsPVEkre/59ki4Yc39mtgzABNBK\n+F+RNNvMvmFmUyQtlbS9mLYAtFvTb/vd/XMzWylph6RTJa1z97cK6wxAWzU91NfUxjjmB9quIyf5\nAJi4CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQhB8IqqNTdGPymTt3brK+cuXKurXe3t7kuhs2bEjWH3nkkWR9165dyXp0\n7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiWZuk1s72SRiUdlfS5u/fkPJ5ZeieY7u7uZH1gYCBZ\nnz59epHtnOCTTz5J1s8555y2bbvKGp2lt4iTfP7G3Q8U8DwAOoi3/UBQrYbfJf3KzF41s74iGgLQ\nGa2+7Z/v7vvM7C8k/drM/tvdXxr7gOwfBf5hACqmpT2/u+/Lfo9IelbSvHEes9bde/I+DATQWU2H\n38zOMLOvHb8t6TuS3iyqMQDt1crb/hmSnjWz48/zb+7+H4V0BaDtWhrnP+mNMc5fOfPmfelI7QRb\nt25N1s8777xkPfX3NTo6mlz3yJEjyXreOP78+fPr1vK+65+37SprdJyfoT4gKMIPBEX4gaAIPxAU\n4QeCIvxAUAz1TQKnn3563dpll12WXPfJJ59M1mfOnJmsZ+d51JX6+8obbrv//vuT9c2bNyfrqd76\n+/uT6953333JepUx1AcgifADQRF+ICjCDwRF+IGgCD8QFOEHgmKK7kngscceq1tbtmxZBzs5OXnn\nIEybNi1Zf/HFF5P1BQsW1K1dcsklyXUjYM8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzj8BzJ07\nN1m/9tpr69byvm+fJ28s/bnnnkvWH3jggbq1999/P7nua6+9lqx//PHHyfpVV11Vt9bq6zIZsOcH\ngiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByr9tvZuskLZI04u4XZ8vOlrRF0ixJeyXd4O7pQVdx3f56\nuru7k/WBgYFkffr06U1v+/nnn0/W864HcOWVVybrqe/NP/7448l1P/zww2Q9z9GjR+vWPv300+S6\nef9deXMOlKnI6/b/XNI1X1h2u6Sd7j5b0s7sPoAJJDf87v6SpINfWLxY0vrs9npJSwruC0CbNXvM\nP8Pdh7PbH0iaUVA/ADqk5XP73d1Tx/Jm1iepr9XtAChWs3v+/WbWJUnZ75F6D3T3te7e4+49TW4L\nQBs0G/7tkpZnt5dL2lZMOwA6JTf8ZrZJ0suSvmVmQ2b2A0k/lXS1mb0r6e+y+wAmkNxx/kI3FnSc\n/6KLLkrW77nnnmR96dKlyfqBAwfq1oaHh+vWJOnee+9N1p9++ulkvcpS4/x5f/dbtmxJ1m+66aam\neuqEIsf5AUxChB8IivADQRF+ICjCDwRF+IGguHR3AaZOnZqspy5fLUkLFy5M1kdHR5P13t7eurXB\nwcHkuqeddlqyHtWFF15Ydgttx54fCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8Ac+bMSdbzxvHz\nLF68OFnPm0YbGA97fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+AqxevTpZN0tfSTlvnJ5x/Oac\nckr9fduxY8c62Ek1secHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByx/nNbJ2kRZJG3P3ibNkqSf8g\n6cPsYXe6+7+3q8kqWLRoUd1ad3d3ct286aC3b9/eVE9IS43l5/0/2b17d9HtVE4je/6fS7pmnOX/\n4u7d2c+kDj4wGeWG391fknSwA70A6KBWjvlXmtnrZrbOzM4qrCMAHdFs+NdI+qakbknDkh6s90Az\n6zOzQTNLTxoHoKOaCr+773f3o+5+TNLPJM1LPHatu/e4e0+zTQIoXlPhN7OuMXe/K+nNYtoB0CmN\nDPVtkrRA0tfNbEjSPZIWmFm3JJe0V9KKNvYIoA1yw+/uy8ZZ/EQbeqm01Dz2U6ZMSa47MjKSrG/Z\nsqWpnia7qVOnJuurVq1q+rkHBgaS9TvuuKPp554oOMMPCIrwA0ERfiAowg8ERfiBoAg/EBSX7u6A\nzz77LFkfHh7uUCfVkjeU19/fn6zfdtttyfrQ0FDd2oMP1j0jXZJ0+PDhZH0yYM8PBEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0Exzt8BkS/Nnbqsed44/Y033pisb9u2LVm/7rrrkvXo2PMDQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCM8zfIzJqqSdKSJUuS9VtuuaWpnqrg1ltvTdbvuuuuurUzzzwzue7GjRuT\n9d7e3mQdaez5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3HF+M7tA0gZJMyS5pLXu/pCZnS1pi6RZ\nkvZKusHdP25fq+Vy96ZqknTuuecm6w8//HCyvm7dumT9o48+qlu74oorkuvefPPNyfqll16arM+c\nOTNZf++99+rWduzYkVz30UcfTdbRmkb2/J9L+kd3/7akKyT90My+Lel2STvdfbakndl9ABNEbvjd\nfdjdd2W3RyW9I+l8SYslrc8etl5S+jQ2AJVyUsf8ZjZL0hxJv5M0w92PzzP1gWqHBQAmiIbP7Tez\naZK2SvqRux8aez67u7uZjXvga2Z9kvpabRRAsRra85vZV1UL/kZ3fyZbvN/MurJ6l6SR8dZ197Xu\n3uPuPUU0DKAYueG32i7+CUnvuPvqMaXtkpZnt5dLSl9KFUClWN4wlZnNl/QbSW9IOpYtvlO14/5f\nSLpQ0p9UG+o7mPNc6Y1V2PXXX1+3tmnTprZue//+/cn6oUOH6tZmz55ddDsnePnll5P1F154oW7t\n7rvvLrodSHL39HfMM7nH/O7+W0n1nuxvT6YpANXBGX5AUIQfCIrwA0ERfiAowg8ERfiBoHLH+Qvd\n2AQe5099dfWpp55Krnv55Ze3tO28S4O38v8w9XVgSdq8eXOyPpEvOz5ZNTrOz54fCIrwA0ERfiAo\nwg8ERfiBoAg/EBThB4JinL8AXV1dyfqKFSuS9f7+/mS9lXH+hx56KLnumjVrkvU9e/Yk66gexvkB\nJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8wOTDOP8AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3PCb\n2QVm9oKZvW1mb5nZLdnyVWa2z8x2Zz8L298ugKLknuRjZl2Sutx9l5l9TdKrkpZIukHSYXd/oOGN\ncZIP0HaNnuTzlQaeaFjScHZ71MzekXR+a+0BKNtJHfOb2SxJcyT9Llu00sxeN7N1ZnZWnXX6zGzQ\nzAZb6hRAoRo+t9/Mpkl6UdI/u/szZjZD0gFJLumfVDs0+H7Oc/C2H2izRt/2NxR+M/uqpF9K2uHu\nq8epz5L0S3e/OOd5CD/QZoV9scdql459QtI7Y4OffRB43HclvXmyTQIoTyOf9s+X9BtJb0g6li2+\nU9IySd2qve3fK2lF9uFg6rnY8wNtVujb/qIQfqD9+D4/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAULkX8CzYAUl/GnP/69myKqpqb1XtS6K3ZhXZ2182+sCO\nfp//Sxs3G3T3ntIaSKhqb1XtS6K3ZpXVG2/7gaAIPxBU2eFfW/L2U6raW1X7kuitWaX0VuoxP4Dy\nlL3nB1CSUsJvZteY2e/NbI+Z3V5GD/WY2V4zeyObebjUKcayadBGzOzNMcvONrNfm9m72e9xp0kr\nqbdKzNycmFm61NeuajNed/xtv5mdKukPkq6WNCTpFUnL3P3tjjZSh5ntldTj7qWPCZvZX0s6LGnD\n8dmQzOx+SQfd/afZP5xnufuPK9LbKp3kzM1t6q3ezNLfU4mvXZEzXhehjD3/PEl73P2P7n5E0mZJ\ni0voo/Lc/SVJB7+weLGk9dnt9ar98XRcnd4qwd2H3X1XdntU0vGZpUt97RJ9laKM8J8v6c9j7g+p\nWlN+u6RfmdmrZtZXdjPjmDFmZqQPJM0os5lx5M7c3ElfmFm6Mq9dMzNeF40P/L5svrtfJunvJf0w\ne3tbSV47ZqvScM0aSd9UbRq3YUkPltlMNrP0Vkk/cvdDY2tlvnbj9FXK61ZG+PdJumDM/ZnZskpw\n933Z7xFJz6p2mFIl+49Pkpr9Him5n//n7vvd/ai7H5P0M5X42mUzS2+VtNHdn8kWl/7ajddXWa9b\nGeF/RdJsM/uGmU2RtFTS9hL6+BIzOyP7IEZmdoak76h6sw9vl7Q8u71c0rYSezlBVWZurjeztEp+\n7So347W7d/xH0kLVPvH/H0k/KaOHOn39laT/yn7eKrs3SZtUexv4v6p9NvIDSedI2inpXUn/Kens\nCvX2r6rN5vy6akHrKqm3+aq9pX9d0u7sZ2HZr12ir1JeN87wA4LiAz8gKMIPBEX4gaAIPxAU4QeC\nIvxAUIQfCIrwA0H9H/00nuWz++2XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "X_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Image standardisation\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoa5K7ynWpfq",
        "colab_type": "text"
      },
      "source": [
        "One hot encoding the labels from training and test set. Each 1d label is converted to 10d sparse matrix. Eg, digit 2 becomes [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "outputId": "c16711d3-8881-45c6-f98e-04c89160faec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(y_train[1])\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "Y_train[1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LumrLeKF065o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = X_train.shape[0]\n",
        "\n",
        "def custom_loss(custom_model, lamda):\n",
        "  model_layers = custom_model.layers # type list where each el is Conv2D obj etc.\n",
        "  #print(model_layers)\n",
        "  reg_wts = 0\n",
        "  \n",
        "  for idx, layer in enumerate(model_layers):\n",
        "    layer_wts = model_layers[idx].get_weights() # type list\n",
        "    #print(len(layer_wts), layer_wts)\n",
        "    \n",
        "    if len(layer_wts) > 0: # activation, dropout layers do not have any weights\n",
        "      layer_wts = model_layers[idx].get_weights()[0] #type ndarray, 3,3,1,16 : layer1 output\n",
        "      reg_wts += np.sum(layer_wts**2)\n",
        "      \n",
        "  print(\"Lambda: %f, Reg. loss: %f\" %(lamda, reg_wts) )   \n",
        "  reg_wts = reg_wts * (lamda/(2*m))\n",
        "      \n",
        "  def total_loss(y_true, y_pred):   \n",
        "    return K.categorical_crossentropy(y_true, y_pred) + reg_wts\n",
        "  \n",
        "  return total_loss     \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bL3JTX3_c8-L",
        "colab": {}
      },
      "source": [
        "def build_model_with_param_lamda(lamda):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3), use_bias=False, input_shape=(28,28,1))) #26\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), use_bias=False)) #24\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(10, (1, 1), activation='relu', use_bias=False))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#10\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#8\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#6\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#4\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(10, (4, 4))) \n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  model.compile(loss=custom_loss(model, lamda), optimizer='adam', metrics=['accuracy']) \n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKki0i88_U3",
        "colab_type": "text"
      },
      "source": [
        "#### Grid search for custom_loss parameter lambda\n",
        "lamda=0.006 is best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA37fJFR2JqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "5c5d58a7-c0eb-4fdc-cad3-c83ed78ae32a"
      },
      "source": [
        "keras_model = KerasClassifier(build_fn=build_model_with_param_lamda, epochs=50, batch_size=128, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "lamda = [0.006, 0.008, 0.01, 0.02]\n",
        "param_dist = dict(lamda=lamda)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=keras_model, param_grid=param_dist, n_jobs=-1)\n",
        "print(\"GridSearch created\")\n",
        "start = time.time()\n",
        "grid_search.fit(X_train, Y_train)\n",
        "print(\"GridSearchCV took %.2f seconds\"\n",
        "      \" parameter settings.\" % ((time.time() - start)))\n",
        "\n",
        "# Show the results\n",
        "print(\"Best score: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
        "print()\n",
        "\n",
        "means = grid_search.cv_results_['mean_test_score']\n",
        "stds = grid_search.cv_results_['std_test_score']\n",
        "params = grid_search.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    \n",
        "score = grid_search.score(X_train, Y_train)\n",
        "print(score)\n",
        "\n",
        "# all_train, all_test = list(), list()\n",
        "# all_train.append(train_acc)\n",
        "# all_test.append(test_acc)\n",
        "# plot train and test means\n",
        "# plt.plot(values, all_train, label='train', marker='o')\n",
        "# plt.plot(values, all_test, label='test', marker='o')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearch created\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 10:15:10.215602 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0904 10:15:10.241031 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 10:15:10.245853 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0904 10:15:10.290861 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0904 10:15:10.292107 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0904 10:15:10.800428 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0904 10:15:10.890008 140388723337088 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0904 10:15:11.027540 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0904 10:15:11.779885 140388723337088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Lambda: 0.006000, Reg. loss: 223.272539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0904 10:15:12.074058 140388723337088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV took 4236.49 seconds parameter settings.\n",
            "Best score: 0.992467 using {'lamda': 0.006}\n",
            "0.992467 (0.000239) with: {'lamda': 0.006}\n",
            "0.991083 (0.000572) with: {'lamda': 0.008}\n",
            "0.991583 (0.001592) with: {'lamda': 0.01}\n",
            "0.991683 (0.000419) with: {'lamda': 0.02}\n",
            "0.9985333333015441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DewXJhfhAE9H",
        "colab": {}
      },
      "source": [
        "def build_model_with_param_lr(learn_rate):\n",
        "  print(\"Learning rate\", learn_rate)\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3), use_bias=False, input_shape=(28,28,1))) #26\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), use_bias=False)) #24\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(10, (1, 1), activation='relu', use_bias=False))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#10\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#8\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#6\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#4\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(10, (4, 4))) \n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  optimizer = Adam(lr=learn_rate)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-rCnprupym",
        "colab_type": "text"
      },
      "source": [
        "#### Randomized search values for optimizer parameter 'lr'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4f074549-c26e-4c85-a1cc-221eb7674518",
        "id": "-31hmprBujb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "keras_model = KerasClassifier(build_fn=build_model_with_param_lr, epochs=50, batch_size=128, verbose=0)\n",
        "\n",
        "# define the random search parameters\n",
        "learn_rate = [0.0005, 0.0007, 0.001, 0.002, 0.003]\n",
        "\n",
        "param_dist = dict(learn_rate=learn_rate)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=keras_model, param_distributions=param_dist,\n",
        "                                   n_jobs=-1, iid=False)\n",
        "\n",
        "print(\"Starting random search training\")\n",
        "start = time.time()\n",
        "random_search.fit(X_train, Y_train)\n",
        "print(\"RandomizedSearchCV took %.2f seconds\"\n",
        "      \" parameter settings.\" % ((time.time() - start)))\n",
        "\n",
        "# Show the results\n",
        "print(\"Best score: %f using %s\" % (random_search.best_score_, random_search.best_params_))\n",
        "print()\n",
        "\n",
        "means = random_search.cv_results_['mean_test_score']\n",
        "stds = random_search.cv_results_['std_test_score']\n",
        "params = random_search.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting random search training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning rate 0.0005\n",
            "RandomizedSearchCV took 5057.05 seconds parameter settings.\n",
            "Best score: 0.992517 using {'learn_rate': 0.0005}\n",
            "0.992517 (0.000290) with: {'learn_rate': 0.0005}\n",
            "0.991517 (0.000779) with: {'learn_rate': 0.0007}\n",
            "0.991267 (0.000193) with: {'learn_rate': 0.001}\n",
            "0.991900 (0.000816) with: {'learn_rate': 0.002}\n",
            "0.991350 (0.000579) with: {'learn_rate': 0.003}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teKaribXnrEb",
        "colab_type": "code",
        "outputId": "16dfc483-2dac-41c4-c7ca-9cb520ab5187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.21.3\n",
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc6n_kfexx0e",
        "colab_type": "text"
      },
      "source": [
        "#### Passing callback to keras classifier wrapper for scikit-learn - done for checkpoint, but the variable monitored could be only training accuracy or loss. Hence was not useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSg0kSSqvcCK",
        "colab_type": "code",
        "outputId": "34be9eb2-5ba3-4d7f-863d-1396c7240bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath = dir + \"GridSearch-{epoch:02d}-{acc:.4f}.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, period=2, mode='max')\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=10)\n",
        "keras_model = KerasClassifier(build_fn=build_model_with_param_lr, epochs=50, batch_size=128, verbose=0, \n",
        "                              callbacks=[early_stopper])\n",
        "\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.0001, 0.0003, 0.0005, 0.0007, 0.0009]\n",
        "param_dist = dict(learn_rate=learn_rate)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=keras_model, param_grid=param_dist, verbose=1,\n",
        "                           iid=False, n_jobs=-1)\n",
        "\n",
        "print(\"Starting grid search training\")\n",
        "\n",
        "start = time.time()\n",
        "#grid_search.fit(X_train, Y_train, callbacks=[checkpoint])\n",
        "grid_search.fit(X_train, Y_train)\n",
        "print(\"GridSearchCV took %.2f seconds\"\n",
        "      \" parameter settings.\" % ((time.time() - start)))\n",
        "\n",
        "# Show the results\n",
        "print(\"Best score: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting grid search training\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 77.4min finished\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 19:20:44.615673 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0901 19:20:44.641700 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0901 19:20:44.645416 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0901 19:20:44.686624 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0901 19:20:44.688248 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning rate 0.0007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0901 19:20:45.447993 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0901 19:20:45.592709 140489569757056 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0901 19:20:45.813680 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0901 19:20:46.675599 140489569757056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0901 19:20:46.801595 140489569757056 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.4975 - acc: 0.8523\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.85230, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-01-0.8523.hdf5\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.1046 - acc: 0.9688\n",
            "\n",
            "Epoch 00002: acc improved from 0.85230 to 0.96882, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-02-0.9688.hdf5\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0736 - acc: 0.9781\n",
            "\n",
            "Epoch 00003: acc improved from 0.96882 to 0.97808, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-03-0.9781.hdf5\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0584 - acc: 0.9820\n",
            "\n",
            "Epoch 00004: acc improved from 0.97808 to 0.98200, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-04-0.9820.hdf5\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0524 - acc: 0.9839\n",
            "\n",
            "Epoch 00005: acc improved from 0.98200 to 0.98392, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-05-0.9839.hdf5\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0458 - acc: 0.9854\n",
            "\n",
            "Epoch 00006: acc improved from 0.98392 to 0.98538, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-06-0.9854.hdf5\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0428 - acc: 0.9867\n",
            "\n",
            "Epoch 00007: acc improved from 0.98538 to 0.98667, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-07-0.9867.hdf5\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0397 - acc: 0.9874\n",
            "\n",
            "Epoch 00008: acc improved from 0.98667 to 0.98738, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-08-0.9874.hdf5\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0385 - acc: 0.9877\n",
            "\n",
            "Epoch 00009: acc improved from 0.98738 to 0.98773, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-09-0.9877.hdf5\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0348 - acc: 0.9892\n",
            "\n",
            "Epoch 00010: acc improved from 0.98773 to 0.98923, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-10-0.9892.hdf5\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0347 - acc: 0.9889\n",
            "\n",
            "Epoch 00011: acc did not improve from 0.98923\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0308 - acc: 0.9897\n",
            "\n",
            "Epoch 00012: acc improved from 0.98923 to 0.98975, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-12-0.9897.hdf5\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0313 - acc: 0.9900\n",
            "\n",
            "Epoch 00013: acc improved from 0.98975 to 0.98997, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-13-0.9900.hdf5\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0296 - acc: 0.9907\n",
            "\n",
            "Epoch 00014: acc improved from 0.98997 to 0.99068, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-14-0.9907.hdf5\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0289 - acc: 0.9909\n",
            "\n",
            "Epoch 00015: acc improved from 0.99068 to 0.99092, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-15-0.9909.hdf5\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0278 - acc: 0.9910\n",
            "\n",
            "Epoch 00016: acc improved from 0.99092 to 0.99102, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-16-0.9910.hdf5\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0274 - acc: 0.9910\n",
            "\n",
            "Epoch 00017: acc did not improve from 0.99102\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0262 - acc: 0.9914\n",
            "\n",
            "Epoch 00018: acc improved from 0.99102 to 0.99145, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-18-0.9914.hdf5\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0252 - acc: 0.9919\n",
            "\n",
            "Epoch 00019: acc improved from 0.99145 to 0.99190, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-19-0.9919.hdf5\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0257 - acc: 0.9922\n",
            "\n",
            "Epoch 00020: acc improved from 0.99190 to 0.99222, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-20-0.9922.hdf5\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0244 - acc: 0.9922\n",
            "\n",
            "Epoch 00021: acc did not improve from 0.99222\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0230 - acc: 0.9927\n",
            "\n",
            "Epoch 00022: acc improved from 0.99222 to 0.99267, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-22-0.9927.hdf5\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0225 - acc: 0.9928\n",
            "\n",
            "Epoch 00023: acc improved from 0.99267 to 0.99278, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-23-0.9928.hdf5\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0221 - acc: 0.9926\n",
            "\n",
            "Epoch 00024: acc did not improve from 0.99278\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0235 - acc: 0.9924\n",
            "\n",
            "Epoch 00025: acc did not improve from 0.99278\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0217 - acc: 0.9929\n",
            "\n",
            "Epoch 00026: acc improved from 0.99278 to 0.99293, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-26-0.9929.hdf5\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0203 - acc: 0.9933\n",
            "\n",
            "Epoch 00027: acc improved from 0.99293 to 0.99327, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-27-0.9933.hdf5\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0198 - acc: 0.9934\n",
            "\n",
            "Epoch 00028: acc improved from 0.99327 to 0.99342, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-28-0.9934.hdf5\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0197 - acc: 0.9936\n",
            "\n",
            "Epoch 00029: acc improved from 0.99342 to 0.99363, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-29-0.9936.hdf5\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0197 - acc: 0.9934\n",
            "\n",
            "Epoch 00030: acc did not improve from 0.99363\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0205 - acc: 0.9935\n",
            "\n",
            "Epoch 00031: acc did not improve from 0.99363\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0182 - acc: 0.9940\n",
            "\n",
            "Epoch 00032: acc improved from 0.99363 to 0.99397, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-32-0.9940.hdf5\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0180 - acc: 0.9942\n",
            "\n",
            "Epoch 00033: acc improved from 0.99397 to 0.99422, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-33-0.9942.hdf5\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0176 - acc: 0.9942\n",
            "\n",
            "Epoch 00034: acc improved from 0.99422 to 0.99425, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-34-0.9942.hdf5\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0186 - acc: 0.9937\n",
            "\n",
            "Epoch 00035: acc did not improve from 0.99425\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0175 - acc: 0.9941\n",
            "\n",
            "Epoch 00036: acc did not improve from 0.99425\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0181 - acc: 0.9941\n",
            "\n",
            "Epoch 00037: acc did not improve from 0.99425\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0176 - acc: 0.9943\n",
            "\n",
            "Epoch 00038: acc improved from 0.99425 to 0.99427, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-38-0.9943.hdf5\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0172 - acc: 0.9943\n",
            "\n",
            "Epoch 00039: acc improved from 0.99427 to 0.99428, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-39-0.9943.hdf5\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0164 - acc: 0.9946\n",
            "\n",
            "Epoch 00040: acc improved from 0.99428 to 0.99457, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-40-0.9946.hdf5\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0163 - acc: 0.9949\n",
            "\n",
            "Epoch 00041: acc improved from 0.99457 to 0.99490, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-41-0.9949.hdf5\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0166 - acc: 0.9945\n",
            "\n",
            "Epoch 00042: acc did not improve from 0.99490\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0160 - acc: 0.9948\n",
            "\n",
            "Epoch 00043: acc did not improve from 0.99490\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0161 - acc: 0.9948\n",
            "\n",
            "Epoch 00044: acc did not improve from 0.99490\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0154 - acc: 0.9950\n",
            "\n",
            "Epoch 00045: acc improved from 0.99490 to 0.99503, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-45-0.9950.hdf5\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0158 - acc: 0.9946\n",
            "\n",
            "Epoch 00046: acc did not improve from 0.99503\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0156 - acc: 0.9951\n",
            "\n",
            "Epoch 00047: acc improved from 0.99503 to 0.99512, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-47-0.9951.hdf5\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0155 - acc: 0.9946\n",
            "\n",
            "Epoch 00048: acc did not improve from 0.99512\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0143 - acc: 0.9954\n",
            "\n",
            "Epoch 00049: acc improved from 0.99512 to 0.99545, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-49-0.9954.hdf5\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.0147 - acc: 0.9952\n",
            "\n",
            "Epoch 00050: acc did not improve from 0.99545\n",
            "GridSearchCV took 5162.65 seconds parameter settings.\n",
            "Best score: 0.992283 using {'learn_rate': 0.0007}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jokeMUyIWtph",
        "colab_type": "text"
      },
      "source": [
        "#### Image normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC8_F-2ctU5B",
        "colab_type": "code",
        "outputId": "7e31d935-8c90-4eb4-f6c1-30e27e17804a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Entire dataset mean and standard deviation\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))\n",
        "\n",
        "# Create generator to normalize images\n",
        "# feature-wise is per-dataset, sample-wise is per-image\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "# Calculate mean, var on training dataset, required if featurewise_center/featurewise_std_normalization set to True\n",
        "datagen.fit(X_train)\n",
        "print('Train data generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.310)\n",
            "Train data generator mean=0.131, std=0.308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeQt9looB8EN",
        "colab_type": "code",
        "outputId": "31afa405-1eb6-432e-e3e6-640f92ac36d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# get batch of the training set\n",
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True, seed=42) # default is true\n",
        "batchX, batchy = train_iterator.next()\n",
        "\n",
        "valid_iterator = datagen.flow(X_test, Y_test, batch_size=batch_size, shuffle=True, seed=42)\n",
        "\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(valid_iterator)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=469, test=79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoYsjsa8odyD",
        "colab_type": "text"
      },
      "source": [
        "### Final run for 40 epochs with lambda 0.006 and lr=0.0005"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RMfSDhynccDN",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3), use_bias=False, input_shape=(28,28,1))) #26\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), use_bias=False)) #24\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(10, (1, 1), activation='relu', use_bias=False))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#10\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#8\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#6\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), use_bias=False))#4\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(10, (4, 4))) \n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-FPeqHLiY2E",
        "colab_type": "text"
      },
      "source": [
        "#### Best validation accuracy was 99.54% which came at epoch 32, with training accuracy at 99.39%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFCLeb8SLH0c",
        "colab_type": "code",
        "outputId": "2cc8ae39-903c-4eb6-bcf5-0e8d4a19e53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "custom_model = build_model()\n",
        "#custom_model.summary()\n",
        "custom_model.compile(loss=custom_loss(custom_model, lamda=0.006), optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n",
        "\n",
        "file = dir + \"GridSearch-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model_hist = custom_model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator),                     \n",
        "                    validation_data=valid_iterator, validation_steps=len(valid_iterator),\n",
        "                    epochs=40, verbose=1, callbacks=[checkpoint])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lambda: 0.006000, Reg. loss: 221.904478\n",
            "Epoch 1/40\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.6137 - acc: 0.8188 - val_loss: 0.1550 - val_acc: 0.9576\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.95760, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-01-0.9576.hdf5\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1418 - acc: 0.9594 - val_loss: 0.0620 - val_acc: 0.9810\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.95760 to 0.98100, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-02-0.9810.hdf5\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0894 - acc: 0.9736 - val_loss: 0.0589 - val_acc: 0.9822\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98100 to 0.98220, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-03-0.9822.hdf5\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0683 - acc: 0.9795 - val_loss: 0.0380 - val_acc: 0.9887\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98220 to 0.98870, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-04-0.9887.hdf5\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0570 - acc: 0.9831 - val_loss: 0.0327 - val_acc: 0.9899\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98870 to 0.98990, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-05-0.9899.hdf5\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0514 - acc: 0.9837 - val_loss: 0.0246 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.98990 to 0.99260, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-06-0.9926.hdf5\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0443 - acc: 0.9861 - val_loss: 0.0256 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99260\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0417 - acc: 0.9870 - val_loss: 0.0233 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.99260 to 0.99310, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-08-0.9931.hdf5\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0390 - acc: 0.9877 - val_loss: 0.0265 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99310\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0363 - acc: 0.9885 - val_loss: 0.0260 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99310\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0345 - acc: 0.9892 - val_loss: 0.0204 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.99310 to 0.99390, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-11-0.9939.hdf5\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0320 - acc: 0.9896 - val_loss: 0.0223 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99390\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.0254 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99390\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0202 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99390\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0290 - acc: 0.9908 - val_loss: 0.0225 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99390\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0279 - acc: 0.9911 - val_loss: 0.0245 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99390\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0279 - acc: 0.9911 - val_loss: 0.0203 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.99390 to 0.99450, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-17-0.9945.hdf5\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0256 - acc: 0.9917 - val_loss: 0.0195 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99450\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0248 - acc: 0.9915 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99450\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0241 - acc: 0.9918 - val_loss: 0.0193 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99450\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0249 - acc: 0.9919 - val_loss: 0.0208 - val_acc: 0.9944\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99450\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0247 - acc: 0.9916 - val_loss: 0.0230 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99450\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0225 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99450\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.0196 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99450\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0191 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.99450 to 0.99460, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-25-0.9946.hdf5\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0191 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99460\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0209 - acc: 0.9929 - val_loss: 0.0263 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99460\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0207 - acc: 0.9931 - val_loss: 0.0197 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99460\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0220 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99460\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0205 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99460\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0169 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99460\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0169 - val_acc: 0.9954\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.99460 to 0.99540, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign5/GridSearch-32-0.9954.hdf5\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0204 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99540\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0183 - acc: 0.9938 - val_loss: 0.0216 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99540\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0256 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99540\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0180 - acc: 0.9941 - val_loss: 0.0188 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99540\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.0184 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99540\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0180 - acc: 0.9941 - val_loss: 0.0183 - val_acc: 0.9949\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99540\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0241 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99540\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0171 - acc: 0.9941 - val_loss: 0.0180 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9CpK5YkuX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7a216849-51e0-481c-a042-7ed9f5cb6914"
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(10,4))\n",
        "    # Set axis properties [xmin, xmax, ymin, ymax]\n",
        "    axs[0].axis([0,40,0.95,1])\n",
        "    \n",
        "    # Plot training & validation accuracy values    \n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    \n",
        "    \n",
        "    # Plot training & validation loss values\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    #axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "plot_model_history(model_hist)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAEWCAYAAAA5GNBmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8lNXVwPHfyWSSCSQhkAQIBAib\nCiiCbO4iLsV9361bK7bVt1rr29rX1lq1detq1bbYulVRcd/AHXeQRRHZQQQStoRANsiETHLeP+4T\nDCHLJGSyzJzv5zOfzDzrGZSHk3vvuVdUFWOMMcYY0zHFtXcAxhhjjDGmYZasGWOMMcZ0YJasGWOM\nMcZ0YJasGWOMMcZ0YJasGWOMMcZ0YJasGWOMMcZ0YJasmYgSkRwRURGJD+PYK0Tkk7aIyxhjIsWe\ne6a1WbJmdhORtSKyS0Qy6mz/0nvw5LRPZHvEkiwiZSIys71jMcZ0fh35udecpM9EN0vWTF3fAhfV\nfBCRg4Au7RfOXs4BKoATRKR3W97YHpjGRK2O/twzMc6SNVPXf4HLan2+HHii9gEi0k1EnhCRAhFZ\nJyK/FpE4b59PRP4oIltFZA1wSj3n/kdENonIBhG5U0R8zYjvcuCfwCLg0jrX7iciL3pxFYrIA7X2\nXS0iy0SkVESWisgh3nYVkSG1jntMRO703k8UkTwR+aWIbAYeFZHuIvK6d4/t3vvsWuf3EJFHRWSj\nt/9lb/tiETmt1nF+789odDO+uzEmMjr6c28vIpIoIn/1njUbvfeJ3r4M79lUJCLbROTjWrH+0ouh\nVERWiMhx+xKHaRuWrJm65gCpIjLMe5hcCDxZ55i/A92AQcAxuIfcld6+q4FTgdHAWODcOuc+BoSA\nId4xJwI/DCcwERkATASe8l6X1drnA14H1gE5QF/gGW/fecBt3vGpwOlAYTj3BHoDPYABwBTc35lH\nvc/9gXLggVrH/xf3G/kIoCfwF2/7E+yZXJ4MbFLVL8OMwxgTOR32udeIW4BDgVHAwcB44Nfevp8D\neUAm0Av4P0BFZH/gOmCcqqYA3wPW7mMcpi2oqr3shaqC+0t7PO4v/F3AZOAdIB5QXBLkA3YBw2ud\ndw3wgff+feBHtfad6J0bj3toVABJtfZfBMzy3l8BfNJIfL8GFnrv+wJVwGjv82FAARBfz3lvAdc3\ncE0FhtT6/Bhwp/d+ovddA43ENArY7r3PAqqB7vUc1wcoBVK9z88Dv2jv/+b2slesvzryc8+7tzbw\nXPsGOLnW5+8Ba733twOv1H62eduHAPne9/W395+9vcJ/2RgcU5//Ah8BA6nTFQBkAH5cC1aNdbjk\nCVxSkltnX40B3rmbRKRmW1yd4xtzGfAwgKpuEJEPcd0VXwL9gHWqGqrnvH64B1tLFKhqsOaDiHTB\ntZZNBrp7m1O838b7AdtUdXvdi6jqRhH5FDhHRF4CTgKub2FMxpjW11Gfew3pU088fbz39+F6E972\n7jlVVe9W1dUicoO3b4SIvAXcqKob9zEWE2HWDWr2oqrrcANuTwZerLN7K1CJewDV6A9s8N5vwiUt\ntffVyMX9hpmhqmneK1VVRzQVk4gcDgwFfiUim70xZBOAi72B/7lA/waKAHKBwQ1ceid7DiSuW7Sg\ndT7/HNgfmKCqqcDRNSF69+khImkN3OtxXFfoecBsVd3QwHHGmDbWEZ97TdhYTzwbve9Sqqo/V9VB\nuGEfN9aMTVPVaap6pHeuAvfsYxymDViyZhryA2CSqu6ovVFVq4DpwO9FJMUbR3Yj343vmA78VESy\nRaQ7cHOtczcBbwN/EpFUEYkTkcEickwY8VyO65oYjut6HAUcCCThWqnm4h6Yd4tIVxEJiMgR3rn/\nBm4SkTHiDPHiBliIS/h8IjIZNxalMSm4cWpFItID+G2d7zcTeMgrRPCLyNG1zn0ZOATXolb3N3dj\nTPvraM+9GoneM63mFQc8DfxaRDLFTTtya008InKq95wToBg3ZKRaRPYXkUleIUIQ9yyrbuafkWkH\nlqyZeqnqN6o6v4Hd/wPsANYAnwDTgEe8fQ/jxoh9BXzB3r+hXgYkAEuB7bixW1mNxSIiAeB84O+q\nurnW61tc18Xl3sP0NNyYjPW4wbUXeN/lOeD3XpyluKSph3f5673zioBLvH2N+SsuQdyKG5T8Zp39\n38f9Br4cNzbkhpodqloOvIDrZqn752KMaWcd6blXRxkusap5TQLuBObjKuO/9u57p3f8UOBd77zZ\nwEOqOgtIBO7GPb8244qgftWMOEw7EdW6vTzGmEgRkVuB/VT10iYPNsYYY8AKDIxpK1636Q9wrW/G\nGGNMWCLWDSoij4hIvogsbmC/iMj9IrJaRBaJN0mpt+9yEVnlvS6PVIzGtBURuRo30Himqn7U3vEY\nY4zpPCLWDeoNrC4DnlDVA+vZfzJuDMDJuKq+v6nqBK/1YT5uYkEFFgBj6psOwRhjjDEm2kWsZc1r\nPdjWyCFn4BI5VdU5QJqIZOEm9ntHVWvmq3oHN6eVMcYYY0zMac8xa33Zc1LAPG9bQ9v3IiJTcEsA\n0bVr1zEHHHBAZCI1xnRICxYs2Kqqme0dR2vIyMjQnJyc9g7DGNNGmvP86tQFBqo6FZgKMHbsWJ0/\nv6GKa2NMNBKRdU0f1Tnk5ORgzzBjYkdznl/tOc/aBvac8Tnb29bQdmOMMcaYmNOeydqrwGVeVeih\nQLE30/NbwIneDPDdcQvivtWOcRpjjDHGtJuIdYOKyNPARCBDRPJwy/L4AVT1n8AMXCXoatz6jFd6\n+7aJyB3APO9St6tqY4UKxhhjjDFRK2LJmqpe1MR+Ba5tYN8jfLeMhzHGGGOiTGVlJXl5eQSDwfYO\nJaICgQDZ2dn4/f4WX6NTFxgYY4wxpnPKy8sjJSWFnJwc3Jrz0UdVKSwsJC8vj4EDB7b4OraQuzHG\nGGPaXDAYJD09PWoTNQARIT09fZ9bDy1ZM8YYY0y7iOZErUZrfEdL1owxphNZmFvEH99aQfmuqvYO\nxRjTRixZM8aYTmTpxhIemLWakmBle4diTKdWVFTEQw891OzzTj75ZIqKiiIQUcMsWTPGmE4k4HeP\n7WCltawZsy8aStZCoVCj582YMYO0tLRIhVUvS9aMMaaZRGSyiKwQkdUicnMDx5wvIktFZImITGut\neyf5fQCUW7JmzD65+eab+eabbxg1ahTjxo3jqKOO4vTTT2f48OEAnHnmmYwZM4YRI0YwderU3efl\n5OSwdetW1q5dy7Bhw7j66qsZMWIEJ554IuXl5RGJ1abuMMaYZhARH/AgcAKQB8wTkVdVdWmtY4YC\nvwKOUNXtItKzte4fSPCSNRuzZqLI715bwtKNJa16zeF9UvntaSMa3H/33XezePFiFi5cyAcffMAp\np5zC4sWLd0+x8cgjj9CjRw/Ky8sZN24c55xzDunp6XtcY9WqVTz99NM8/PDDnH/++bzwwgtceuml\nrfo9wFrWjDGmucYDq1V1jaruAp4BzqhzzNXAg6q6HUBV81vr5jUta8HK6ta6pDEGGD9+/B5zod1/\n//0cfPDBHHrooeTm5rJq1aq9zhk4cCCjRo0CYMyYMaxduzYisVnLmjHGNE9fILfW5zxgQp1j9gMQ\nkU8BH3Cbqr5Z90IiMgWYAtC/f/+wbh7YnaxZy5qJHo21gLWVrl277n7/wQcf8O677zJ79my6dOnC\nxIkT650rLTExcfd7n88XsW5Qa1kzxpjWFw8Mxa2PfBHwsIjsNSJZVaeq6lhVHZuZmRnWhW3MmjGt\nIyUlhdLS0nr3FRcX0717d7p06cLy5cuZM2dOG0e3J2tZM8aY5tkA9Kv1OdvbVlse8LmqVgLfishK\nXPI2b19vvjtZszFrxuyT9PR0jjjiCA488ECSkpLo1avX7n2TJ0/mn//8J8OGDWP//ffn0EMPbcdI\nLVkzxpjmmgcMFZGBuCTtQuDiOse8jGtRe1REMnDdomta4+a7p+4IWbJmzL6aNq3+Qu3ExERmzpxZ\n776acWkZGRksXrx49/abbrqp1eOrYd2gxsSSndtg1Tug2t6RdFqqGgKuA94ClgHTVXWJiNwuIqd7\nh70FFIrIUmAW8L+qWtga97dqUGNij7WsGRMLVGHhNHjnN7CzEMZdDSfdC3H2+1pLqOoMYEadbbfW\neq/Ajd6rVSVZgYExMceSNWOiXcEKeP1nsO5T6DcBhp0O8x6GynI4/X6I87V3hFAVgpIN0H1Ae0fS\n4fl9cfjixKbuMCaGWLJmTLTatRM+/iN8ej8kdIXT7ofR3wcRSO4FH94NoXI461/g87dPjCWb4Isn\nYMFjULoRLpwGB5zSPrF0Ikl+n1WDGhNDLFkzba9kI+TOheFnuMQhUlQjc/1QBayfA9+8D2s+gJTe\nMOnX0Pug1r9Xc1SFoHg9bPsWCr+B2Q9A0To4+GI48Q7omvHdscf+CvwBePc2933OfQTiExu8dENU\nFQnjz7gkWMl7y7Yw4+vN7Kqs4oo+6zly+yv4V80ArYLBkyCpO7xyLWSNgm59m775tx81O95oEbBk\nzZiYYsmaaVvVVfDs92HDfNfKc+pfwdfK/xuWF8Enf4Z5/4HjboUJ1+z7NbeuhtXvwOr3XHdi5U6I\ni4fs8S5x++dRcPBFMOkW6Ja97/cLR8lGmPMQbFkC29ZAUa5LfGpk7A+Xvw4Dj6r//CN/Bv4uMPMX\n8MzFcMGT4E9q8rblu6qYuXgTz87LZf667QzJTGZkdjfvlcYBWSkkxvsoLq/k3aVbmPH1Jj5etZWM\nqnwu7jqf06rfY0DuBrZrMp93OxvfuKs4bPx4kkvXwr+OhhenwOWvNt49u+kreLpuAWbsCPjjbMya\nMTHEkjXTtuY/4hK1IcfDl/+Fsnw471HXTbevQhUw79/w0X0uYUsf7BKRpB4w8ryWXbOyHN67A+Y8\n6D6nD4HRl8Lg4yDnCEhMgfLt8PGf4fN/wZIXYcKP4KgbIdBt379TfYIl8OnfYPaDUB1yLXp9x8CB\n50KPgdB9oPuZklVvy+IerWETrnEJ2qs/hafOc12i9bRqqSqLN5Tw7Pz1vPLlRkorQgxI78Jlhw1g\n7dYdvL88n+cW5AHg9wmDMpJZs7WMtKrtXJS8gNvS5tJvx9dQBZo9jtzBP+fpHYfw8tfb2PjGdhLf\neoejhmZwSp8bOWvdHSx+5jcUHHIDGcmJpCcnUBoMsbGonI3F5ZRvWsUFX/+QCgKR+fPtBJL8PkvW\njGljycnJlJWVtcu9LVmLZgseg6+fh6P/FwYd097RQPEGePd3rsvrkudd4jbjJnj8NLh4+p7ddM1R\nXe2SpPdud91+g46FE26HjP3gyXPg5R9Bl+4uQWyODV/ASz+CrStg7A/giOvrHwCf1N11M46/Gt6/\nEz79qxuHdez/wbgf7nNX7K5QNWsLd9AnJZ7kxU/CB3fDzq0uOTvuN9A9Z4/jS4OVrM4vY/2ajWwq\nDrKpqJwNRUE2FZezqThIabCSft27MDCjq3tlHsO4I//M0E9vQv4ynPK0oRT0PIJ1aRNYGRhJftDH\nx6u2snRTCYnxcZx8UBYXjOvHhIE9did9qsqGonIW5RWzKHc7PVa/yAk93ien7EskVA09RsCE38CB\nZyM9BtEP+AVw08nKF+u389pXG/l49VZuLTkQqo/g9BUPcdvX6czXA/b4bpls5/nE31ElIW5Pvwc3\nxVnsSUrw2dQdxsQQ0SiZb2ns2LE6f/789g6j49jwBfznRPe+uhKGngjH/w56DW/Z9T7+MyyaDpc8\nB2n9mj6+LlXX1fbNLPjJbNfyA7D8DXj+KkjtC5e+8N32GtXVsHkRrJnlWuHqs342bPwSeh3okrQh\nx323L1gMj57iugkvfw2yxzQda1UlfPwn+PBeNxD/jAf2vGZTNi50U2R8+xEcewsc84vwz62lsKyC\naZ+v57+z1zJ65yf8Mv4ZBsVtZknCSGb1/x8S+o+hX/cubC2rYHV+GasLylidX8aWkoo9rpMSiKdP\ntySy0gJkdUsiNRBP7vadrCnYwdrCHburCgfJRibFfcnRcYsYH7ecgFRSofEs0AP4ImUiaYdfwWmH\n5NAtqZFihO3r3LiztR9Dj8Fw0Lkw4mzoeUDD59QRLCvC9/AxaGgXnxz/Elsqu5ASiKdvUiUHvn0R\n8UXfIpe/BtljEZEFqjq2JX++HU1znmHn/3M2vjjh6SntO6u6Mfti2bJlDBs2rN3uf/PNN9OvXz+u\nvfZaAG677Tbi4+OZNWsW27dvp7KykjvvvJMzzjgD2LeWtfq+a3OeX5asRaOKUjeGqqoSfvgufD0d\nPvoT7CqFUZe4Fp/UPuFfb/3n8Ohk0GrXWnXlm9A1vXkxLX0Vpn/fJVNHXL/39Z++wI0Bu+Q5SO7t\nBu9/875L0nZ6c4kmpNTfStU1w7Uejryg/nFOpVvgkRNd9+FVb0Hmfg3HWbACXrrGJX8HnQ8n3+ta\nzpqruhpe+Ql89TSc8mcY94OwT122qYRHP/2WVxbmMan6c37Z9Q1yKlezrcsgXsq4hpnBg/i2cCeF\nO3btPqdrgo8hPZMZ3DOZIT2TGZKZTE5GV7K6BUgJNJxcVVcrm0uCfLvVJW4JvjjSkxPokVBNn+KF\npG36GP+37yMFy1wX8PG3wQGn7v3fQRUWPgUzbwYUJt/tuotb2qq44Qv4zwmw/0lw/n9dF/eT50Du\nHLj42d2tpLGarF32yFxKyit5+dojIhyVMZGzRwIz82bY/HXr3qD3QXDS3Q3u/vLLL7nhhhv48MMP\nARg+fDhvvfUW3bp1IzU1la1bt3LooYeyatUqRKRdkzXrBu1oivPcwPF+41t+jTd+7roDr3gDUrNc\ncjT6+/DRH2HuVNc1evh1LsFpqgKwogxemuIGzZ/8R1ccMO18NwA83HFm5UUw43/dX5xDr917f/8J\ncNXb7h/jfx/vxmEBdO0JQ05w3aaDJkJKr73PDUdKL/j+S66l8cmzXcJWe1xWWb6r6vzmfVjykht0\nf97jMOLMlt0PqELYeOQ99NlRiO+Nn7uEcvgZ9R67oyLEqvwylm8q4eWFG5i/Jp9zE+bwcdc36Fmx\nDlKHwJEP0WPkBfzAF09N2le8s5Lc7TtJT06gd2ogrKrMuuLihD5pSfRJS+KIIXW7obNg9EkuEVv5\nFrxzKzx7KfQ71HX71vw/WpbvxrytnAkDjoQzH9r3+dL6HgLH/da1UM77t/vvs+4TOPvfze/OjkJJ\n/jjyS6wb1Jh9MXr0aPLz89m4cSMFBQV0796d3r1787Of/YyPPvqIuLg4NmzYwJYtW+jdu3e7xmrJ\nWkey7HV4+SdQUQJn/RMObsF4nK+egUXPwsRfwYDDv9vepQdM/gNMmOIGzH90H2xeDOc/AfEJDV/v\n7Vtc19aVM9z1znvU/YP97PfhomcaP7fGe7+DHflw0dMNV35m7gc/fMcllGn9XILWc0TrzbDfY5Dr\nZn30FJcUnngHrP0Evnlv929zlYnd+bLrRN7t+2NkfS9S81eTnBhPSiCebkl+JgxKJzmx6b8yn6za\nyp1vLGX55lICXMSzSesYPv0q/tnvPoLZh9M7NcCm4iArt5SyYkspudvKAUhkFz9Mns3UtNdIDW6E\ntAPhqEddkldPi2G3Ln66dYlQEUNtIrD/ZJckLXwSZv3BtXoNO91te+93Lqn/3l2uuKK1/psddp1L\n0mZ46+1NvrvlhSJRJmAFBibaNNICFknnnXcezz//PJs3b+aCCy7gqaeeoqCggAULFuD3+8nJySEY\nDLZLbLVZshZp29dBt36N/wMW2uXmu5rzIPQZDQnJ8PKP3USlB54T/r0Kv4HXb4QBR7hWs/p0z4Fz\n/wMDDnMtcC/8AM59tP4kasWbrkjhiOu/S/wOOMVNt/HaT10331lTG/9u62a7QoJDr3WtJY1J6Q2n\n/DGcb9oyWQfDRdNcsvbUuRDnh/6HwnG3Mit0ENe8u4tAhR9/WSWlFWvZFdpzhvjkxHjOOaQv3z8s\nhyE9k/e6/KotpfxhxjJmrSggu3sSvzl1ODsqQrxY8Cd6rL6Wq3L/j4vW/IZFVTnExwmDM5MZ1a87\nPzzQx1ElrzNg3Qv4yguh9zg46i+w3/ciOw9dc/niYcwVrrBh9gNust1lr7r/Z8/6F2Tu37r3i4tz\nv7Q8cYZLWA/9cetevxOzSXGNaR0XXHABV199NVu3buXDDz9k+vTp9OzZE7/fz6xZs1i3bl17hwhY\nshZZS16G5y53rTpjr3Ljxbr02POYovXw3JVuOovx17gWn+oQPHkuvHA1+BJg2GlN3yu0C56/0rV0\nnf1w00sIjfuhG9P25s2um7PuOTu2wqvXuUH7x96y57ljLnfViO/dDl0yYPJd9ScVoQp47XqXrB77\nf01/h7Yw8Gi4cqb7fjlHoAnJPPD+av70zkoOHZTOvy4dS7cuboxXRaiKsmDITRtRXM5z8/N4em4u\nj89ex1FDM7jssBwmHdCT7Tt38dd3V/L03Fy6+H386qQDuPzwHAL+mj/PoVA8Ex75Hq+E/kLh+a+R\nmjWEhLXvw7y/w9x3vNark2H8FBdjR0rS6kpMhok3w5grXdfksNMjtwJCck9XkGL2EPBbNagxrWHE\niBGUlpbSt29fsrKyuOSSSzjttNM46KCDGDt2LAccEH5xVCRZshYpNa1lPQa5sVdv/9pN6zDibDfY\nvO8YNw7opWvcwP09xkglwiXT4b9nuUTuwqdcK0tj3vudmyj0wmnhzf4OrqUiVAHv/hZ8iXDGg641\nQ9UlWcFiuOyV+se1HXkjlBXA5/9wxQajLnFj08q3Q9D7+e3HbtqLi59z/8B3FNluPGdlVTW3vLCI\n6fPzOGt0X+4+5yAS479LWBPjfSQm+0hPTiQnoyuHD87g/04exrPz1vPknPVc/cR8+qYlUVJeyc7K\nKi6Z0J/rjxtKenI9f17d+sKlLyKPfI+MF84FiXOrDST3cq2gYy5vu8l0W0tKr+a1/JpW47pBbW1Q\nY1rD119/V9iQkZHB7Nn1/4LYXnOsgSVrkfPF47D9W5eo7HeiGx82/z9u+ouvprnKusLVbtD9eY+7\nCVxrS0xxc5E9cYY3Puzp+qePUIWVb7puqXFXN39dxSNvcAnbB39wrSOn/tVVMC5/HU68E3qNqP88\nEfjeH1wL2/t3uld9Drncff82UF2tlAZDFO6oYPvOXZSUh+jXI4mc9K7E+/bsqi0JVnLtU1/w8aqt\n/HTSEH52wn5hDdDPTEnkuklDueaYwbyzdAvTPl9PSiCen5+4f71do3uevJ/7b/rk2e6/+4m3u8rK\n9lqX03RaSX4fu6qqqapWfHEduBXWGNMqLFmLhIpS+PAeVxk39AS3rfeBcOpf3NQVi551SduQ493c\nZ/4GZmJPSnNVjI+f7uYou+R56DnMTSux4Qv3c+MXULbFDcY/sYGEqSnH/AKqKtzcYqEKN/fZgCPr\nr9ysLS4OznjIddtVh9wUF4E09zOpu4u/GbP4qyort5QR8MfRKzVQqxtxTwWlFSzZWMySjSUs3lDM\nmoIdFO7Yxfadu6iq3nsqmsT4OPbrlcKwrBSGZaWSk96Ve95czur8Mu49ZyTnj2v+vHF+n5sc9uSD\nspp3YvYY+OXajt3NaTq8pAT3y0ewsoquYRS9GGM6N/tbHgmzH4QdBa5asu4/yokpbrzYuB+Gd60u\nPeCyl+GxU+GJ012XKQDi5jwbPMkN8B5xdsNJX1NEYNJvXKI2+wE3n9lZ/wivqi8+AQ65rGX39QQr\nq3hl4QYe/XQtyzeX7t7eLclPr9REeqUG6JkSoGjnLhZvLN5j0tcB6V0Y2jOFQwak0aNrAt27JJCe\n7H6mBOJZV7iTZZtKWLaplPeW5TN9vlsSKSUxnkevHMdRQzP3KfYWsUTN7KMk7xeZckvWTCe3x/J3\nUao15rO1v+WtrSwfPvu7G3Sd3UpzdXbNcGPHPrvfjXHqewj0HgmB1Na5PrgE4sQ73bipzAMgrX/r\nXbsBm4uD/HfOWqZ9vp7tOys5oHcKd555IInxceSXVrClJMjm4iBbSitYtWUryYF4Dh+cwYg+qYzo\n043hfVIbn00fGDPgu4IOVaWgrIIVm0sZlJlM37SmFy03piNK9JI1m77DdGaBQIDCwkLS09OjNmFT\nVQoLCwkE9m0tY0vWWtuH97rFv4/7beteN6UXfO/3rXvNukT2eXqETcXlfLm+iIW5RSxcX8TOyhAp\niX6SA26+stSAn+TEeNZt28nMrzdRpcoJw3px5REDOXRQj4j+hRUReqa4VjpjOrMkS9ZMFMjOziYv\nL4+CgoL2DiWiAoEA2dn7VkBmyVprKvwGFjzqKvsyhrR3NBGnqizbVMonqwv4Yl0RX+Zu391FmRAf\nx4g+qWQmJ1JWESJ3205KgyFKg5WUVYTomhDPFYfncPnhOfTr0aWdv4kxncvubtBdVhFqOi+/38/A\ngQObPtBYstaq3r/TzYt2zC/bO5KIKQlW8smqrXywIp8PVxbsTs4GpHfhsEHpjOqXxuj+3RmWlUpC\nfP1j3lQVVbfUkTGm+WqKb4Iha1kzJhZENFkTkcnA3wAf8G9VvbvO/gHAI0AmsA24VFXzvH33ADXz\nUNyhqs9GMtZ9tuELWPKimzMrpX3XEGtt1dXKa4s28tTn61mwbjtV1UpKIJ6jh2ZyzP6ZTNwvk56p\n4XctioiNsTdmH9RUg9rEuMbEhoglayLiAx4ETgDygHki8qqqLq112B+BJ1T1cRGZBNwFfF9ETgEO\nAUYBicAHIjJTVUsiFe8+UXUTy3ZJh8N/2t7RtKr5a7dxxxvL+Cq3iMGZXbnm6EFM3L8nh/RP22vu\nMmNM2wjUqgY1xkS/SLasjQdWq+oaABF5BjgDqJ2sDQdu9N7PAl6utf0jVQ0BIRFZBEwGpkcw3pZb\n9Q58+xFMvqd1KzTb0brCHdw9czkzF2+md2qAP513MGeN7mtdl8Z0AAErMDAmpkQyWesL5Nb6nAdM\nqHPMV8DZuK7Ss4AUEUn3tv9WRP4EdAGOZc8kDwARmQJMAejfP/JTTdRr8Yvw8k/cigRjr2yfGJop\nWFnFis2lVKvi98WREB+H3xdHvJeIPTF7LY99tha/L44bT9iPq48aRFJCE2uNGmPajFWDGhNb2rvA\n4CbgARG5AvgI2ABUqerbIjK+vCJAAAAgAElEQVQO+AwoAGYDez2VVHUqMBVg7Nix+z7rXHNUV8MH\nd8FH90K/CXDBk/WvodkBVFUrSzYW8+nqQj77Zitzv91GRajhKjIROH9MP35+4n7NGotmTKwIYzzu\nFcB9uGcawAOq+u/Wuv931aCWrBkTCyKZrG0Aaq/jk813Dy4AVHUjrmUNEUkGzlHVIm/f74Hfe/um\nASsjGGvzVJS5BdiXvw6jLoVT/9zhEjVV5f3l+Tw3P4/ZawopLq8EYP9eKVw8oT8TBvYg0e+jMlRN\nZZVSWVXtvZRDBqRxQO/o6M41prWFOR4X4FlVvS4SMXxXDWpTdxgTCyKZrM0DhorIQFySdiFwce0D\nRCQD2Kaq1cCvcJWhNQ/DNFUtFJGRwEjg7QjGGr7t69w6nflL4Xt3uUlkO1hp44J127h75nLmrd1O\nr9REThzeiyOHZnDY4HSbENaYfRfOeNyISoy3alBjYknEkjVVDYnIdcBbuK6CR1R1iYjcDsxX1VeB\nicBdIqK4btCalcP9wMfebPYluCk9QpGKNWzrPoNnL4WqEFzynFuIvQNZnV/KvW+u4O2lW8hITuSO\nMw/kwnH98FvVpjGtKZzxuADniMjRuF6Bn6lqbt0DWjruNi5OCPjjbMyaMTEiomPWVHUGMKPOtltr\nvX8eeL6e84K4itCOo7rKtagl9YCLp3eoFQo2FZfz13dW8dyCXLokxPPzE/bjqiMH2gLPxrSf14Cn\nVbVCRK4BHgcm1T1oX8bdBvw+m7rDmBhh/5qHK38plG+Hk+7tMIla8c5KHvpwNY99uhZVuOLwgVw3\naQg9uia0d2jGRLNwxuMW1vr4b+De1g4iye+zljVjYoQla+HKnet+Zo9r3zhw5fqPfbaWh2atprQi\nxFmj+vKzE/azNTaNaRvhjMfNUtVN3sfTgWWtHUSS30d5pRUYGBMLLFkLV+5c6NoTuue0Wwihqmpe\n+CKPv7yzis0lQY7dP5NfTD6AYVlWuWlMWwlzPO5PReR0IIRbSu+K1o4j0e+zAgNjYoQla+HKmwv9\nxrdL5eeuUDWvfbWRf3z4DavzyxjVL42/XjiKQwelt3ksxpiwxuP+ClfhHjFJ/jgqbCF3Y2KCJWvh\n2LEVtq2BQy5v09uWBit5eu56HvlkLZtLguzfK4V/XjqG743ohXSw6UKMMW0rKcFa1oyJFZashaNm\nvFq/+qrzW9/m4iCPfvot0z5fT2lFiMMGpXPXOQcxcb9MS9KMMQAE4n0U7axs7zCMMW3AkrVw5M2F\nuHjoMyqitymrCPGnt1fw5Jx1VFUrJx+UxZSjBzEyOy2i9zXGdD6BBKsGNSZWWLIWjty5kHUw+JMi\ndotZy/P59cuL2VhczoXj+vOTiYOtutMY0yA3dYdVgxoTCyxZa0pVJWz4AsZcEZHLby2r4PbXlvLq\nVxsZ0jOZ5390GGMG9IjIvYwx0SPJJsU1JmZYstaUzV9DqNxVgrYiVeXFLzZwxxtL2VER4objh/Lj\niYNJjPe16n2MMdHJlpsyJnZYstaUvHnuZysma9XVyk+e+oI3l2zmkP5p3HPOSIb2Smm16xtjol9N\ny5qqWuGRMVHOkrWm5M6FlD7QLbvVLvn8gjzeXLKZG0/Yj+uOHUJcnD1ojTHNE0jwoQoVoWoCfmuR\nNyaaxbV3AB1e7txWbVXbvmMXd81cxtgB3S1RM8a0WMAbMmFdocZEP0vWGlOyCYrXt2qyds+byykJ\nhrjzrAMtUTPGtFhSQk2yZhWhxkQ7S9Yak9e6k+EuWLedZ+blctURORzQ29bzNMa0XJLX9WkVocZE\nP0vWGpM7F3yJ0HvkPl8qVFXNr19eTO/UADccv18rBGeMiWUBv3t825JTxkQ/S9YakzsX+oyG+IR9\nvtRjn61l2aYSfnvacLomWl2HMWbf1BQVBG0xd2OiniVrDQlVwKaF0G/cPl9qc3GQv7yzkon7ZzL5\nwN6tEJwxJtbVdIMGrWXNmKhnyVpDNi2Cql2Qve/FBXe8vpRQtfK700fYfEjGmFYRsDFrxsQMS9Ya\nkvu5+7mPlaAfrizgja83ce2xQxiQ3rUVAjPGGKsGNSaWWLLWkLy5kNYfUlrebbmpuJxbX1nMwIyu\nXHPMoFYMzhgT66wa1JjYYSPd66Pqigtyjmz2qVXVyocr85n2+XreX56PiPDEVeNtzU9jTKtKrKkG\ntWTNmKhnyVp9ivOgdFOzxqttKi5n+rw8np23no3FQTKSE/nRMYO5cFx/+qd3iWCwxphYVNOyVmHJ\nmjFRz5K1+jRzvNp/56zjt68splrhqKEZ/ObU4Rw/vBd+n/UyG2MiY3eBgVWDGhP1LFmrT9488HeB\nXgc2eWhlVTX3v7eK0f2785fzR1krmjGmTfh9ccTHiXWDGhMDrOmnPrlzoc8h4Gs6l3136RYKSiv4\n8TGDLVEzxrSpJL/PqkGNiQGWrNVVWQ6bF4XdBTpt7nqyugWYuH9mhAMzxpg9BRJ81rJmTAywZK2u\nef+B6lBYydq6wh18vGorF47rT7yNTzPGtLGAP46gJWvGRD3LMGpUVcLrN8Lbt8DQE2HwcU2e8vTc\nXHxxwgXj+rVBgMaYjkJEJovIChFZLSI3N3LcOSKiIjI2EnEk+X1WYGBMDLACA4Cd22D6ZbD2Yzj8\np3D8bRDX+Lxou0LVPDc/l0kH9KR3t0CbhGmMaX8i4gMeBE4A8oB5IvKqqi6tc1wKcD3weaRiSfL7\nbCF3Y2KAtazlL4OpE11RwVn/ghPvaDJRA3hryWYKd+zi4gn9Ix+jMaYjGQ+sVtU1qroLeAY4o57j\n7gDuAYKRCiRgLWvGxITYTtZWzIR/Hw+hIFw5Aw6+MOxTp32+nuzuSRw91AoLjIkxfYHcWp/zvG27\nicghQD9VfaOxC4nIFBGZLyLzCwoKmh1IwO+zMWvGxIDYTda+fh6evgjSh8DVsyA7/CElawrKmL2m\nkIvG98cXJxEM0hjT2YhIHPBn4OdNHauqU1V1rKqOzcxs/i9+NnWHMbEhdsesrZgBKVlw5UxIaN78\naE/PXU98nHDe2OwIBWeM6cA2ALWrirK9bTVSgAOBD0QEoDfwqoicrqrzWzOQJJu6w5iYENGWtaYq\npkRkgIi8JyKLROQDEcmute9eEVkiIstE5H7xnnqtJlgMqVnNTtSClVU8vyCPE4b3omeKFRYYE4Pm\nAUNFZKCIJAAXAq/W7FTVYlXNUNUcVc0B5gCtnqiBm7rDkjVjol/EkrVaFVMnAcOBi0RkeJ3D/gg8\noaojgduBu7xzDweOAEbifkMdBxzTqgEGiyHQrdmnvbl4M9t3VnLJhAGtGo4xpnNQ1RBwHfAWsAyY\nrqpLROR2ETm9LWOxMWvGxIZIdoPurpgCEJGaiqna5e3DgRu997OAl733CgSABEAAP7ClVaMLFkO3\n5ndjTvt8PQPSu3D44PRWDccY03mo6gxgRp1ttzZw7MRIxZFkyZoxMSGS3aBNVkwBXwFne+/PAlJE\nJF1VZ+OSt03e6y1VXVb3BvtUSdWClrVVW0qZu3YbF43vT5wVFhhj2lnA76OySglVWZGBMdGsvatB\nbwKOEZEvcd2cG4AqERkCDMMN3O0LTBKRo+qevE+VVMFiSExt1inT5q7H7xPOHWOFBcaY9pfkd3NC\nBkOWrBkTzZpM1kTkf0Skewuu3VTFFKq6UVXPVtXRwC3etiJcK9scVS1T1TJgJnBYC2KoX2XQza3W\njJa1qmrl5S83cOKI3mQkJ7ZaKMYY01KBBJes2cS4xkS3cFrWeuGWU5nuVXeG2//XaMUUgIhkeHMS\nAfwKeMR7vx7X4hYvIn5cq9te3aAtVlHifjYjWVu2qYTtOys5YVivVgvDGGP2RSDePT5t3Jox0a3J\nZE1Vfw0MBf4DXAGsEpE/iMjgJs4Lp2JqIrBCRFbiksLfe9ufB74BvsaNa/tKVV9r5ndrWLDY/Qyk\nhX3KnDWFAEwY1KPVwjDGmH2R5LWsWbJmTHQLqxpUVVVENgObgRDQHXheRN5R1V80cl6jFVOq+jwu\nMat7XhVwTVjfoCV2J2vht6zNWbONnPQuZHVLilBQxhjTPDVj1myuNWOiWzhj1q4XkQXAvcCnwEGq\n+mNgDHBOhOOLjGCR+xlmslZVrcz9tpBDB9l0HcaYjiPgtzFrxsSCcFrWegBnq+q62htVtVpETo1M\nWBHWzJa1ZZtKKAmGLFkzxnQoAWtZMyYmhFNgMBPYVvNBRFJFZAJAfXOfdQrNTNZsvJoxpiPaPXWH\nLeZuTFQLJ1n7B1BW63OZt63zanayZuPVjDEdT8Bv1aDGxIJwkjVRVa35oKrVRHaZqsgLFkOcH/xN\nJ182Xs0Y01HVVINaN6gx0S2cZG2NiPxURPze63pgTaQDi6iapabCmDLOxqsZYzqq77pBLVkzJpqF\nk6z9CDgct/pAHjABmBLJoCKuGeuC2ng1Y0xHZQUGxsSGJrszVTUft/pA9GhWsmbj1YwxHVNizQoG\nNnWHMVGtyWRNRALAD4ARQKBmu6peFcG4IivMZK1mvNrJB2W1QVDGmLbmrcSSp6oVIjIRGAk84a1R\n3OGJCEl+ny3kbkyUC6cb9L9Ab+B7wIe4BdlLIxlUxAVLwkrWbLyaMVHvBaBKRIYAU4F+wLT2Dal5\nkhJ8NimuMVEunGRtiKr+Btihqo8Dp+DGrXVeYbasff6tm17OxqsZE7WqvXWMzwL+rqr/C3SqpvRA\nfJyNWTMmyoWTrFV6P4tE5ECgG9AzciG1gTCTtTlrCm28mjHRrVJELgIuB173tvnbMZ5mCyT4rBrU\nmCgXTrI2VUS6A78GXgWWAvdENKpIClVAqLzJZK26Wpn77TbrAjUmul0JHAb8XlW/FZGBuKEfnUaS\n35I1Y6JdowUGIhIHlKjqduAjYFCbRBVJwRL3s4lkbdnmEorLKy1ZMyaKqepS4KcA3i+lKaraqX4Z\nDfh91g1qTJRrtGXNW63gF20US9vYvdRUWqOHzVlj49WMiXYi8oG33nEP4AvgYRH5c3vH1RyuZc2q\nQY2JZuF0g74rIjeJSD8R6VHzinhkkRLmuqBz1hQywMarGRPtuqlqCXA2bsqOCcDx7RxTswT8Vg1q\nTLQLZ43PC7yf19bapnTWLtGgN31SILXBQ2rGq00e0buNgjLGtJN4EckCzgduae9gWiLgj7Mxa8ZE\nuXBWMBjYFoG0mTBa1naPVxvceRsQjTFhuR14C/hUVeeJyCBgVTvH1CxJNmbNmKgXzgoGl9W3XVWf\naP1w2kAYydru8WoDrbjAmGimqs8Bz9X6vAY4p6nzRGQy8DfAB/xbVe+us/9HuN6IKqAMmOIVM7S6\nJJu6w5ioF86YtXG1XkcBtwGnRzCmyAorWXPj1fqk2Xg1Y6KZiGSLyEsiku+9XhCR7CbO8QEPAicB\nw4GLRGR4ncOmqepBqjoKuBeIWNGCVYMaE/3C6Qb9n9qfRSQNeCZiEUVasBji4sHfpd7dNl7NmJjy\nKG55qfO8z5d6205o5JzxwGqvFQ4ReQY4AzcHJQBe0UKNrrhxvhER8KpBVRURidRtjDHtKJyWtbp2\nAJ13HFvN6gUNPNRsvJoxMSVTVR9V1ZD3egzIbOKcvkBurc953rY9iMi1IvINrmXtp/VdSESmiMh8\nEZlfUFDQoi+Q5PcBUGGLuRsTtZpM1kTkNRF51Xu9DqwAXop8aBHSxFJTawp2ADAsq+FqUWNM1CgU\nkUtFxOe9LgUKW+PCqvqgqg4GfolbAaa+Y6aq6lhVHZuZ2VSOWL+A3z3GbfoOY6JXOFN3/LHW+xCw\nTlXzIhRP5DWRrG0pCQLQOzXQVhEZY9rPVcDfgb/guio/A65o4pwNQL9an7O9bQ15BvhHy0NsXE3L\nWnllFd0jdRNjTLsKJ1lbD2xS1SCAiCSJSI6qro1oZJHSRLKWX1pBYnwc3ZI61VrOxpgWUNV11CmY\nEpEbgL82cto8YKi3jugG4ELg4jrXGKqqNVOAnEIEpwNJSnDJmlWEGhO9whmz9hxQezBEFbVK3Tud\nMFrWeqUGbKCuMbHrxsZ2qmoIuA43P9syYLqqLhGR20WkJvG7TkSWiMhC73qXRyrYxPjvWtaMMdEp\nnJa1eFXdVfNBVXeJSEIEY4qssJK1xDYMyBjTwTT5m5qqzgBm1Nl2a63310cgrnpZy5ox0S+clrWC\nWr8tIiJnAFsjF1KENZmsVdDTxqsZE8siNs1GJNSMWbPF3I2JXuG0rP0IeEpEHvA+5wH1rmrQ4YV2\nQai8wWRNVdlSEuTY/Xu2cWDGmLYkIqXUn5QJ0Klmw7ZqUGOiXziT4n4DHCoiyd7nsohHFSkV3jyV\ngbR6d5dVhNi5q8q6QY2Jcqqa0t4xtJba1aDGmOgUzjxrfxCRNFUtU9UyEekuIne2RXCtromlpraU\nVADQy7pBjTGdRMCSNWOiXjhj1k5S1aKaD6q6HTg5ciFFUND7Gg0ka/neHGuWrBljOouaAoMKS9aM\niVrhJGs+EdndLygiSUDn7CdsqmWttCZZ65xfzxgTe6xlzZjoF06BwVPAeyLyKG7w7RXA45EMKmLC\n7Aa1alBjTGcRiK8pMLBqUGOiVTgFBveIyFfA8bjqqbeAAZEOLCKaTNaCJCfGk5wYTg5rjDHtL94X\nR4IvjmDIWtaMiVbhdIMCbMElaucBk3CzdjdJRCaLyAoRWS0iN9ezf4CIvCcii0TkAxHJ9rYfKyIL\na72CInJmmLE2LIxkrad1gRpjOplEf5xN3WFMFGuwCUlE9gMu8l5bgWcBUdVjw7mwiPiAB4ETcHOz\nzRORV1V1aa3D/gg8oaqPi8gk4C7g+6o6CxjlXacHsBp4u7lfbi/BYhAf+LvUu3tLSQW9UqwL1BjT\nuST5fbaCgTFRrLGWteW4VrRTVfVIVf07bl3QcI0HVqvqGm+5qmeAM+ocMxx433s/q579AOcCM1V1\nZzPuXb+a1QsaWPfTlpoyxnRGSQmWrBkTzRpL1s4GNgGzRORhETmOMNbMq6UvkFvrc563rbavvPsA\nnAWkiEh6nWMuBJ6u7wYiMkVE5ovI/IKCgqYjamSpKVUlv6TCpu0wxnQ6gXifVYMaE8UaTNZU9WVV\nvRA4ANfqdQPQU0T+ISInttL9bwKOEZEvgWOADdRqvRORLOAgXFFDfTFOVdWxqjo2MzOz6bs1kqwV\n7axkV1W1JWvGmE4nkOCj3NYGNSZqNVlgoKo7VHWaqp4GZANfAr8M49obgH61Pmd722pfe6Oqnq2q\no4FbvG1FtQ45H3hJVSvDuF/TGknWvptjzZI1Y0znkuSPs25QY6JYuNWggFu9wGvNOi6Mw+cBQ0Vk\noIgk4LozX619gIhkiEhNDL8CHqlzjYtooAu0RRpL1nYvNWVj1owxnUvACgyMiWrNStaaQ1VDwHW4\nLsxlwHRVXSIit4vI6d5hE4EVIrIS6AX8vuZ8EcnBtcx92GpBNZqsWcuaMaZzSvL7bOoOY6JYRGd/\nVdUZwIw6226t9f554PkGzl3L3gUJ+6axZK3YJWuZKdayZozpXJL8PpsU15goFrGWtQ4ntAsqd0Ig\nrd7dW0qDpHXx715nzxhjOotEv8+WmzImisVOslZR4n42MmbNJsQ1xnRGNimuMdEtdpK1Jpaayi8J\n0qubJWvGmM4nKSHO5lkzJorFULLmzQjSaMuajVczxnQ+gXgfVdVKZZV1hRoTjWIoWWu4Za2qWiko\ns9ULjDGdU1KCG2trrWvGRKcYStYaHrNWuKOCqmq1OdaMMZ1STWFU0KbvMCYqxVCy1nDL2pZiNyFu\nT2tZM8Z0Qkk1yZotOWVMVLJkDZsQ1xjTPCIyWURWiMhqEbm5nv03ishSEVkkIu+JyIBIxlPTsmbd\noMZEp9hK1sQHCV332vXduqDWDWqMaZyI+IAHgZOA4cBFIjK8zmFfAmNVdSRu4u97IxlTUoJ7lFuy\nZkx0iq1kLdANRPbataWkAhHISLZkzRjTpPHAalVdo6q7gGeAM2ofoKqzVHWn93EOkB3JgHaPWbNk\nzZioFHvJWj3yS4JkJCfi98XOH4cxpsX6Arm1PufR+NJ4PwBm1rdDRKaIyHwRmV9QUNDigKwb1Jjo\nFjvZSROLuFsXqDGmtYnIpcBY4L769qvqVFUdq6pjMzMzW3yfJKsGNSaqRXQh9w6l0WStgixbvcAY\nE54NQL9an7O9bXsQkeOBW4BjVLUikgHtTtZsMXdjolKMtayl1rsrvzRo03YYY8I1DxgqIgNFJAG4\nEHi19gEiMhr4F3C6quZHOqDd3aC2mLsxUSnGkrW9W9Z2harZWrbLukGNMWFR1RBwHfAWsAyYrqpL\nROR2ETndO+w+IBl4TkQWisirDVyuVSTZmDVjolqMdYOm7bW5oMz1Ttgca8aYcKnqDGBGnW231np/\nfFvGE/Cm7rBqUGOiU2y0rFVVQuWOJibEtZY1Y0znlOCLQ8SSNWOiVWwka42sC5pvqxcYYzo5ESHJ\n76PcqkGNiUoxkqwVuZ/1tqxZN6gxpvNL8vtszJoxUSpGkrXG1wWNjxN6dElo46CMMab1BPw+W8jd\nmChlyVpJBT1TEomL23sZKmOM6SwC/jgbs2ZMlIr5ZM3mWDPGRIOkBOsGNSZaxXyytrnYlpoyxnR+\ngXiftawZE6ViPllz64Jay5oxpnOzljVjolfsJGsSBwnJe2wu31VFSTBkyZoxpvP49iN44Ydu/sha\nAjZ1hzFRKzaStYoS16omexYR5JfaHGvGmE6mdDN8/RxsXbnH5oDfR0XIqkGNiUaxkaw1sC7od3Os\n2Zg1Y0wn0Xuk+7lp0R6bk/xx1rJmTJSK8WTNWtaMMZ1MxlCIT4LNdZM1G7NmTLSyZA3olWLJmjGm\nk4jzQa8Re7WsBRKsGtSYaBXzyVpifBypSfHtEJQxxrRQ1sGuZa36uzFqqQE/FaFqtu/Y1Y6BGWMi\nIcaTtQp6pQYQsdULjDGdSNZIVzhVtHb3pmP2ywTgrSWb2ykoY0ykxFCylrbXZjfHmhUXGGM6mXqK\nDEb0SSUnvQuvLdrYTkEZYyIl+pO1qhDsKmtgqakKKy4wxnQ+PYeD+PYoMhARTh3Zh9nfFFJQWtGO\nwRljWlv0J2sVJe5nnWRNVW31AmNM5+QPQOYBexUZnHpwFtUKby7e1E6BGWMiIaLJmohMFpEVIrJa\nRG6uZ/8AEXlPRBaJyAcikl1rX38ReVtElonIUhHJaVEQwSL3MzF1j81lFSF27qqyblBjTOeUNXKv\n6Tv275XCkJ7JvLbIkjVjoknEkjUR8QEPAicBw4GLRGR4ncP+CDyhqiOB24G7au17ArhPVYcB44H8\nFgXSwLqg302Iay1rxphOKOtgKNviVjTwuK7QLOat3bZ7aiJjTOcXyZa18cBqVV2jqruAZ4Az6hwz\nHHjfez+rZr+X1MWr6jsAqlqmqjtbFEUDyVq+9yDraXOsGWM6owZWMjh1ZB9U4Q1rXTMmakQyWesL\n5Nb6nOdtq+0r4Gzv/VlAioikA/sBRSLyooh8KSL3eS11exCRKSIyX0TmFxQU1B9FA8na5t2rF1g3\nqDGmE+p9kPu5+as9Ng/pmcywrFRet6pQY6JGexcY3AQcIyJfAscAG4AqIB44yts/DhgEXFH3ZFWd\nqqpjVXVsZmZm/XewblBjTDQKpEL3gXu1rAGcOjKLL9YXkbe9ZR0SxpiOJZLJ2gagX63P2d623VR1\no6qeraqjgVu8bUW4VriFXhdqCHgZOKRFUTSYrAVJSYyna6KtXmCM6aTqKTIAOG1kH8C6Qo2JFpFM\n1uYBQ0VkoIgkABcCr9Y+QEQyRKQmhl8Bj9Q6N01EaprLJgFLWxRFsBgkDhKS99hcGgyRmuRv0SWN\nMbEtjEr3o0XkCxEJici5EQuk90jYvva7X0o9/dO7MDK7G69bsmZMVIhYsua1iF0HvAUsA6ar6hIR\nuV1ETvcOmwisEJGVQC/g9965Vbgu0PdE5GtAgIdbFEiw2E3bEbfnV61WrbvJGGOaFGal+3rc0I1p\nEQ0ma5T7ufnrvXadOjKLrzcUs3brjoiGYIyJvIimK6o6Q1X3U9XBqlqTiN2qqq96759X1aHeMT9U\n1Ypa576jqiNV9SBVvcKrKG2+BtYFrVbFZ2uCGmOar8lKd1Vdq6qLgOr6LtBqsmoqQr/aa9cpNV2h\nX1vrmjGdXfQP2GogWauqVuIsWTOdXGVlJXl5eQSD0T2nViAQIDs7G7+/QwxdqK/SfUJLLiQiU4Ap\nAP3792/+BZJ7QnLveosM+qYlMWZAd177aiPXHjukJeEZYzqImE3WXDeoJWumc8vLyyMlJYWcnBwk\nSn/5UFUKCwvJy8tj4MCB7R1Oq1LVqcBUgLFjx2qLLtJAkQG4rtDfvbaU1fmlDOmZ0uI4jTHtK/pH\nbQVL6k/WqrFuUNPpBYNB0tPTozZRAzcrf3p6ekdqPWyy0r1N9R4JBSugsnyvXScflIUIvPaVdYUa\n05nFQLJWDIG0vTZXqRLF/76ZGBLNiVqNDvYdm6x0b1NZI0GrIH/vgvleqQHG5/TgxS/z2FERaofg\njDGtIUaStfpa1hSfdYMaY5opnEp3ERknInnAecC/RGRJxALKOtj9rGfcGsB1k4awYXs51z+zkKrq\nlvW0GmPaV3Qna6pw5A0w9Pi9dlWrJWvG7KuioiIeeuihZp938sknU1RUFIGI2kYYle7zVDVbVbuq\narqqjohYMGkD3C+k9VSEAhw1NJNbTx3Ou8u2cM+byyMWhjEmcqI7WROBo2+CwZP22lWlHa5rxZhO\np6FkLRRqvMttxowZpKXtPTzBtICIG7fWQJEBwBVHDOSywwYw9aM1PDN3fRsGZ4xpDdFfDdqA6mrF\nZ7maiSK/e20JSzeWtOo1h/dJ5benNdwodPPNN/PNN98watQo/H4/gUCA7t27s3z5clauXMmZZ55J\nbm4uwWCQ66+/nilTpgCQk5PD/PnzKSsr46STTuLII4/ks88+o2/fvrzyyiskJSW16veIer1Hwvz/\nQFUIfPU/1m89dThrC1U5YL0AABkRSURBVHfy65cX069HF44YktHGQRpjWiq6W9YaYd2gxuy7u+++\nm8GDB7Nw4ULuu+8+vvjiC/72t7+xcuVKAB555BEWLFjA/Pnzuf/++yksLNzrGqtWreLaa69lyZIl\npKWl8cILL7T11+j8skZCKAiFqxo8JN4XxwMXj2ZgRld+/OQCvikoa8MAjTH7ImZb1qqq1bpBTVRp\nrAWsrYwfP36PudDuv/9+XnrpJQByc3NZtWoV6enpe5wzcOBARo1yyyaNGTOGtWvXtlm8UaN3zUoG\ni6DnsAYPSw34eeSKcZz54Kdc9dg8Xv7JEXTvmtBGQRpjWiq2W9YsWTOmVXXt2nX3+w8++IB3332X\n2bNn89VXXzF69Oh650pLTEzc/d7n8zU53s3UI2M/iA80Om6tRr8eXZh62Vg2FQe59D+fs3JLaRsE\naIzZFzGcrGHdoMbso5SUFEpL6//Hvri4mO7du9OlSxeWL1/OnDlz2ji6GOKLh14jGqwIrWvMgO78\n45JD2FhUzin3f8yf31n5/+3deZRU1Z3A8e+v9u6url7pbuiFBkFtFhWDijETAyZKjKJGHTTrmWSS\nORmzORMzzOSM4+QkZ7JM9mQWs5qJJhJNMk4SIgSJmERUUAQUEER26IXel6qu5c4f9zU02DTd0PWq\nuur3OeeeV/Ve1bv3Vlff/vW9791LLJFMcyGVUmcrb4M1Owya6VIoNblVVFRw1VVXMW/ePO65556T\nji1dupREIkFTUxMrVqxg0aJFGSplnqi5CA4+B7+6C57+Dry6Dnqa7RRGI7imqZrf/93V3HDRNL65\ndhfXf+MpNu5td7nQSqmxyNtr1vQGA6UmxkMPPTTi/mAwyKpVq0Y8NnRdWmVlJdu2bTu+/1Of+tSE\nly9vXPo+aN8Dux6HzT85sb+wAmZfBzd+A3wnX59WEQ7yteWXcPOCWv7pF1u57b+e5j2LGvj00guJ\nhPwuV0ApdTr5Haxp15pSKlfUXgrvd1a96m21y0+1bIfDL8CLD4HHC8u+xUhDClefP4XVd7+Zr655\nhR/+6TV+vvEgb5pVydvmVHNNUzVTioOve49Syj15G6wlUzoprlIqR4WnQPhqmHm1fV7aAOu/BBWz\n7KouIygK+vjnG+Zwy4JaHn3+IGtebmbtjhZEtrKgvpS3zanhhoumUl9e6GJFlFKQx8GaXRs006VQ\nSikXLP4naH8Vfv8vUD4D5tx02pfOqy1hXm0J994whx1He1jzcjOrXz7KF3+3gy/+bgd/MbuSOy9v\n4K1N1QR82ogq5Yb8Ddb0mjWlVL4QgZv+AzoPwC8+DJE6qHvDGd4iNE2N0DQ1wsevmc2hzgEe2XiQ\nlRsP8LcPPk9lOMCtb6jjjssamFFZNOq5lFLnJm+DtaTRSXGVUnnEH4I7fwrfXQI/vQM+9ASU1o/5\n7bWlBXzirbP56JJZrN/Vyk+f2c/3nnqN/35yDw3lhcyoLGJGZREzpwxtw0yNhPDoP8VKnbO8Ddbs\n2qDaiCil8khRJbxrJXz/WnhoOXzgdxCKjOsUXo+w+IIqFl9QRUt3lF++cIhth7t5ra2XjXvb6Rs8\nMV9b0OehscIGbzOGgjgnqCsvCug/zEqNUf4GazoprlKuC4fD9PbqmpQZVXUh/OUD8JNb4QfXwfzb\nYPa1UD1vxDtFRz1VJMTfXH3e8efGGFp6Yuxp7WNPWy972/p4ra2PXS09rN3RTDx5Ys63kgI/M6cU\nMbMy7GyLqCkJURUJMSUc1OvhlBomb4M1nRRXKZW3zlsMt/0A/vhVWPtZmyK1MPttdk62mW+BwPjv\n+hQRqiMhqiMhrjzv5DVgE8kUhzoH2NPWZ4O51l72tPbxx92tPPr8wdedq7woQFVxkOpIiOkVhUyv\nKKLR2daXFxD0eY+/1hjDYDJFNJ4CIBLyaa+dyil5G6zpPGsq56xaAUe3Tuw5a+bD279w2sMrVqyg\nvr6eu+66C4D77rsPn8/HunXr6OjoIB6P87nPfY6bbjr93YcqQ+bebFP3Edi9Bnathq2PwKYfQagU\nLvtruOJvIFw1Idn5vB6mVxQxvaKIxRecfKw3lmBvWx8tPVGau2O0dMeOP27ujvL8/g56oifWjBWB\niqIgiVSKWDxFNJE8aaGGoM9DTUmI6uIQ1SUhaiI26KuKhKgqDtoUCREO5u2fQDXJ5O03Ve8GVerc\nLV++nE9+8pPHg7WVK1fy+OOP8/GPf5xIJEJbWxuLFi1i2bJl2tORrSJT7eoHl74PEoOw74/w3Pfh\nqa/An78FF98Bb/wYVM6emPxivYABX4Fd0xQIB33Mqy0BSkZ8izGGzv44e4/12dTWT3N3lIDPQ8jv\nJeTzEPR7CTpDpy09MY52RTnaHWXLwU5Wd0WJJVKvO29hwEtFOEBJgZ9IyH98GynwEfJ7MQYMxtk6\nH1fIT315AQ3lhdSXFVJa6Nfvtkq7vA3WdFJclXNG6QFLlwULFtDS0sLhw4dpbW2lrKyMmpoa7r77\nbtavX4/H4+HQoUM0NzdTU1PjevnUOPkCcN4Sm9p2w9Pfhs0PwfM/hguuh/rLIdYN0W6I9djHsR4I\nRqBsOpROtxPwlk23w6o9R6F5GzS/dCJ1DxvyFC/4C8AXhEAYpl8FTTfAzMUnDcOKCGVFAcqKAixo\nKDu5zNFuu1LD0IoN0S6Y8Wb4i7dCcTVgg73ugcSJnrueKC09tgfvWF+MnmiCnv4oXV0HiUePEh9s\noTvp4/nU+XRJBOHE5XzDr7sDKA76qCsvpLzIT4HfR2HAS2HAS4GzLQz4KPCf2Ffgt9vBRIq+wSR9\nsQR9sQT9g0n6B5OIgFcEr+dECng9VEWC1JYWMK20gKriIL50TRQ60AlbHrY/88FemH87XHwnVJx3\n5vdmkjHQ8RoceA4OPmt7jC98h51TMBie2Lw69tlt2fSJPe8o8jZYsz1rmS6FUpPf7bffziOPPMLR\no0dZvnw5Dz74IK2trWzatAm/309jYyPRaDTTxVTjVTkLbvw6LP4MPHs/PPdd2PkbG2CFIhAshmCJ\n3bbvgT3rIN4/8rk8Pqg8H6ZfCVMuBG8AElGb4s62vw12/MYujeUrgFnX2D+2MxfDYB90H4Luw9Bz\n2G479kHrDug6cCKfQNgGf1t+Zp9PvQTOvw6ZfS0lVXMo8TYzW/ZBah/E90NsP/QesOfuOQLG6X3z\nOAlseRuutGn6lfQEazjQEeVARz8H2p3UMUBn/yDHegcZiCeJxgbxxXsIDHbRZ4J0UEx8lD+3QopS\neqnx9jJN2phmmqmVNuqklTpppVo6SOIhZvx04aOVAHgDJP2FtAXqaA010l7QSGfhDJKFU/B4PHRH\n43QNxOnqt9vOgUESSUNVJMTUkhA1JSFqInZbXuCnrHMLta8+zJR9v8abjNJXcRHJwnqKn/oKsv7L\nDFS/gd4Lb2fggpsIhssp9CYp6j+Cp2svdOw9EcAUTXFSpZOmQPFUu9zZuUjEYKDDBpMDHRB1tj1H\n4OAmG6D1tZ74HhSU2e/rb++xAduCd0PDG8Fzln/4W3bA9sdsGrrcZNoCmHsLzLk57YFbfgdr2rOm\n1Dlbvnw5H/rQh2hra+PJJ59k5cqVVFVV4ff7WbduHfv27ct0EdW5CE+BJZ+Bqz8NyUHwF45816gx\n0NcGnfuhcy90HYRwNVTPtYGabwzriybjsPePNmjb+VvY8euRX1dQZif2bVgEVR+AqjlQ1QQl9bZs\nR7faa/B2rYb1X4Ynv/j6c3j8UFJn04yroaTW9gaW1NlttBP2/Rn2b4Btj8KmHwJQ7PEzJ1DInEDY\nfhaBQvAXgS8K8Q5IdkCiC8TAsCqnAsUkQhUkgmUMBkrxJfsJxNrxRtvxRDsQc/IwrfEGoKQeU1JP\nInw50cEEAwP9DMYGiMeiJAcH8MW7aOp7mYLegePv66KIA6aauCdEyhsAbxB8AaQgRMrjJxpP0n84\nSf8+e71fCpjqeY25nn30mSAPJ6/iweQ1vHRoBgDVLOdm75+49ch6zm9eQewP/0wbEYpoxyMnehkH\nnXAiQIJTRSXE/sBsDhRcwKGCCzlc1ER3QT1GPBhjSBlDyti/y8ZAhD4a47upj+1i2sAr1PTtpGxg\nH4J53bkB+osbiU59M8nay/A3XkFR3Xz8Ph+JfRtIPf8TfNt/hefFh4iF6+louBZ/YYRgMEQoFMLn\nD4LXb78P4iGFEE1AfzxFfzyF99hOyvY9TmH3q/bzrbyU5ktW4BWoObCKojX3wpp7SU57A555tyBz\nb7HfoQkmxoxc+clm4cKFZuPGjWN+/fz7HufWS+u4b9ncNJZKqfTavn07TU1NmS4G8+fPp7KyknXr\n1tHW1saNN95Ib28vCxcuZMOGDaxatYrGxsZzmrpjpLqKyCZjzMKJqEOmjbcNy3nGwJHNNlgqKIfI\nNJuKp47vTtX+dti91vb+lNbbYdrShvH19qSSdph1/wYbhMb7YbAf4n3Ott/2FhaU2VRYbrehEogP\n2DL0t0H/MRvQDrTb3p/CCpuKKqHQ6YkqqbPDyeHqsfUCGWN7Blt3Qtsrdtu53/ZEJWPOdtD2XiaH\nAinjvDVFMgWDhVW0zb6dYzOWMegNkzSGZMqQSBmSyaFtinD7VqbtfwxfrJP2wDRa/VM56qnhiKea\nI8lSYokUvkQfhfFOihIdFCU7KI63U5fYx8zBXcxMvkqIQQB6KaCPQqc0AggIeEkyxbQfr94hU8FL\nqUa2m+m0mFK6TBGdhJ1tER2mmF5e/33we+X4kHWIGNd5nuN275Nc5tlJUF4fUJ5Ownh4JtXEqtTl\nrE4upIWTh+HrpIUbPBt4h3cD8z17ebnoCubcs3pM5x5P+5W/PWspvcFAqYmydeuJu1ArKyt5+umn\nR3ydzrGmxkzEDjNNW3Bu5yksh4tuP7dzeLz2zuia+ed2nnQQOdFDOOua8b0VGwT4gAYnjW4acB0A\nM8ZbTrDBYttOOPwC4SMvEh4cGjY3NujE2FJVzoKpF0PNxUwrqqQqZbgyniSZMsSTxtmmSKQMg4kU\nPdE43dE43QMJugbidA/E6Y8nKfR7KQz6CAe9FAYWEQ/ezQaP0N0/SHf/AH39/fT09dHXN0AyGScS\n8lIS9FIc8hIJeYkEffjDFXgLylgmwi0ee/2kV4R4MkVPNEF3NE5PdAl/iiXY0PEqjSVe5pzNZ3MG\n+Rus6aS4SimllHu8PjssXj0XFrxnTG8RbC+Zf1JcZJ6+mzAmQ+3Twq4NmulSKKUmIxFZKiI7RWS3\niKwY4XhQRB52jj8jIo3ul1IplSvyNljTtUFVrsiV605Hk011FBEv8B3g7cAc4E4ROXXk44NAhzFm\nFvA1YIQr3JVSamzyN1jTSXFVDgiFQhw7diyrgpmJZozh2LFjhEKhTBdlyOXAbmPMHmPMIPAz4NQl\nGm4CHnAePwJcIzqxo1LqLOXlNWvGuU1Y20412dXV1XHw4EFaW1szXZS0CoVC1NVN/O3wZ6kWGDa5\nFweBK073GmNMQkS6gAqgbfiLROTDwIcBGhrOfHm3Uio/5WWwlnI6IXQYVE12fr+fGTPO6r4slQWM\nMfcD94OduiPDxVFKZam0DoOO4SLc6SKyVkS2iMgfRKRu2LGkiGx20mMTWa6UM2Q0KW4uUUplm0NA\n/bDndc6+EV8jIj7sopfHXCmdUirnpC1cGeNFuP8O/NgYcxHwWeDfhh0bMMZc4qRlE1m2pNO1psOg\nSqmz8BwwW0RmiEgAuAM49R/Kx4D3O49vA54wuXxhoVIqrdLZtzSWi3DnAE84j9eNcDwthppMvcFA\nKTVexpgE8FHgcWA7sNIY85KIfFZEhv6x/D5QISK7gb8DXjeyoJRSY5W25aZE5DZgqTHmr53n7wWu\nMMZ8dNhrHgKeMcZ8Q0TeCTwKVBpjjolIAtgMJIAvGGN+NUIexy/OBeYB205TnBKgawL2j3asAdg/\nQefK1vxHO9d485/Icp0u77M5l372k+uzn2uMKTjNeyYVEWkFTl1ItZJTbkrIcflUX61rbhpPXacb\nY6aM6ZXGmLQkbNf/94Y9fy/w7VNeMw34BfAC8A3sXVWlzrFaZzsT2Aucd4b8No5y7P6J2H+G97RO\n4LmyMv8znGtc+U9wuUbMO5d+9vrZjz//XEijtWu5mPKpvlrX3Ezpqms67wY940W4xpjDwDsBRCQM\n3GqM6XSOHXK2e0TkD8AC4NWzLMv/TdD+0Y51TuC5sjX/0c413vwnslyny/tszqWf/fj2Z+tnr5RS\nOSOdw6A+4BXgGmyQ9hzwLmPMS8NeUwm0G2NSIvJ5IGmMuVdEyoB+Y0zMec3TwE3GmJdHyW+jGePq\n9emg+Wcu/3yue6bzz+e6uyHX63eqfKqv1jU3pauuabvBwIztIty3ADtF5BWgGvi8s78J2CgiL2Jv\nPPjCaIGa4/6JrsM4af75mXe+55/PdXdDrtfvVPlUX61rbkpLXdPWs6aUUkoppc6dTgurlFJKKZXF\nNFhTSimllMpiORGsnWlZKxfy3ysiW52lsTa6kN8PRKRFRLYN21cuImtEZJezLXMx7/tE5NCw5cGu\nT0feTl71IrJORF4WkZdE5BPO/rTXf5S8Xam/iIRE5FkRedHJ/1+d/TNE5Bnn+/+wM6u+m/n/SERe\nG1b/S9KRv5OXV0ReEJFfO89dqXsmZLpdS6dMtmFuy2Sb5bZMt1GZ4FabNOmDNRnbslZuWGzs0lhu\n3PHyI2DpKftWAGuNMbOBtaRvxvSR8gb4mjmxPNhv05Q32EmS/94YMwdYBNzl/LzdqP/p8gZ36h8D\nlhhjLgYuAZaKyCLgi07+s4AO4IMu5w9wz7D6b05T/gCfwN6wNMStursqi9q1dPkRmWvD3JbJNstt\nmW6jMsGVNmnSB2uMbVmrnGKMWQ+0n7L7JuAB5/EDwM0u5u0aY8wRY8zzzuMe7C9JLS7Uf5S8XWGs\nXuep30kGWAI84uxP58/+dPm7QkTqgHcA33OeCy7VPQNyul3LZBvmtky2WW7LdBvlNjfbpFwI1mqB\nA8OeH8TFP6AOA6wWkU1il8DKhGpjzBHn8VHsVChu+qiIbHGGN1zpzheRRuxkyc/gcv1PyRtcqr/T\n5b4ZaAHWYCeK7nSmyoE0f/9Pzd8YM1T/zzv1/5qIBNOU/deBTwMp53kFLtbdZdnQrrkt021Y2mWy\nzXJLptsol7nWJuVCsJYN3mSMuRQ7ZHGXiLw5k4Uxdj4WN+dk+U/gPGy39xHgK+nOUOyKF48CnzTG\ndA8/lu76j5C3a/U3xiSNMZdgVwS5HLgwXXmNJX8RmQf8o1OOy4By4B8mOl8RuQFoMcZsmuhzq+yT\ngTYs7TLZZrkp022UW9xuk3IhWDvjslbpNmxprBbgl9gvqNuaRWQqgLNtcStjY0yz8wuaAr5Lmusv\nIn5so/egMeYXzm5X6j9S3m7X38mzEzth9JVAqdgVQ8Cl7/+w/Jc6wzzGGBMDfkh66n8VsExE9mKH\nBJdg1xN2ve4uyXi7lgEZa8PSLZNtVqZkuo1ygattUi4Ea88Bs507MALAHcBjbmUuIkUiUjz0GLgW\n2Db6u9LiMeD9zuP3A//rVsZDDY7jFtJYf+eagO8D240xXx12KO31P13ebtVfRKaISKnzuAB4G/b6\nl3XAbc7L0vazP03+O4b9wRHs9RkTXn9jzD8aY+qMMY3Y3/EnjDHvxqW6Z0BG27UMyVgblk6ZbLPc\nluk2yk2ut0kmC1apP9cEXI9dh/RV4DMu5z0TeNFJL7mRP/BT7HBbHDsm/kHsWPlaYBfwe6Dcxbz/\nB9gKbME2QFPTWPc3YYcLtgCbnXS9G/UfJW9X6g9cBLzg5LMNuHfYd/BZYDfwcyDocv5POPXfBvwE\nCKfr5+/k9xbg127WPRMpk+2aC3XLWBuWgbpmrM3KQF0z2kZlsN5pb5N0uSmllFJKqSyWC8OgSiml\nlFI5S4M1pZRSSqkspsGaUkoppVQW02BNKaWUUiqLabCmlFJKKZXFNFhTWUNEkiKyeViasIWNRaRR\nRDIx/51SKg9o+6XSyXfmlyjlmgFjlylRSqnJRtsvlTbas6aynojsFZEvichWEXlWRGY5+xtF5Aln\nAfG1ItLg7K8WkV+KyItOeqNzKq+IfFdEXhKR1c4M20oplTbafqmJoMGayiYFpwwjLB92rMsYMx/4\nNvB1Z9+3gAeMMRcBDwLfdPZ/E3jSGHMxcCl2ZQmA2cB3jDFzgU7g1jTXRymVP7T9UmmjKxiorCEi\nvcaY8Aj79wJLjDF7nAWRjxpjKkSkDbu0U9zZf8QYUykirUCdsQuLD52jEVhjjJntPP8HwG+M+Vz6\na6aUynXafql00p41NVmY0zwej9iwx0n0mk2llDu0/VLnRIM1NVksH7Z92nn8Z+AO5/G7gaecx2uB\njwCIiFdEStwqpFJKjUDbL3VONDJX2aRARDYPe/47Y8zQ7e9lIrIF+9/lnc6+jwE/FJF7gFbgr5z9\nnwDuF5EPYv8D/QhwJO2lV0rlM22/VNroNWsq6znXfCw0xrRluixKKTUe2n6piaDDoEoppZRSWUx7\n1pRSSimlspj2rCmllFJKZTEN1pRSSimlspgGa0oppZRSWUyDNaWUUkqpLKbBmlJKKaVUFvt/2kxS\nSNPmUIsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiouEcC5ZY_R",
        "colab_type": "code",
        "outputId": "cca21817-f27b-43d4-8636-0d3deec0dd30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "custom_model = build_model()\n",
        "custom_model.compile(loss=custom_loss(custom_model, lamda=0.006), optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n",
        "\n",
        "custom_model.load_weights(dir + \"GridSearch-32-0.9954.hdf5\")\n",
        "print(\"Loaded model from disk \")\n",
        "\n",
        "custom_model.evaluate_generator(generator=valid_iterator, steps=len(valid_iterator),verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lambda: 0.006000, Reg. loss: 223.439027\n",
            "Loaded model from disk \n",
            "79/79 [==============================] - 1s 16ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.016863743467372842, 0.9954]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}