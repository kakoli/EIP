{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "customnet_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olhnbhUl-XFP",
        "colab_type": "text"
      },
      "source": [
        "### Assignment 4 on Tiny Imagenet dataset of 1 lakh training set belonging to 200 classes. Image dim - (64,64)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOqhCr1lzomJ",
        "colab_type": "code",
        "outputId": "e661fc92-31ef-440b-9c8f-26a841b779ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## Imports and initializations\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib  inline\n",
        "\n",
        "# Callbacks\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "#csv_logger = CSVLogger('resnet18_imagenet.csv')\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 200\n",
        "nb_epoch = 50\n",
        "train_size = 100000\n",
        "val_size = 10000\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "dir = \"/content/gdrive/My Drive/Colab Notebooks/EIP_2019/Assignment4/CustomWts/\"\n",
        "filepath = dir + \"{epoch:03d}-{val_acc:.4f}.hdf5\"\n",
        "print(filepath)\n",
        "!ls\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "# The imagenet images are RGB.\n",
        "img_channels = 3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/{epoch:03d}-{val_acc:.4f}.hdf5\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeIgOXgKQRZ2",
        "colab_type": "text"
      },
      "source": [
        "### Loading of imagenet data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYAXseuROo8c",
        "colab_type": "code",
        "outputId": "6012ea00-0b92-4240-a50f-1ef8da3cae6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -qq '/content/gdrive/My Drive/Colab Notebooks/EIP_2019/Assignment4/tiny2-imagenet-200.zip'\n",
        "\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale= 1./255,\n",
        "                                  zoom_range = 0.25,\n",
        "                                  shear_range = 0.1,                           \n",
        "                                  width_shift_range=0.15,\n",
        "                                  height_shift_range=0.15,\n",
        "                                  rotation_range=55,\n",
        "                                  horizontal_flip=True)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_rows, img_cols), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_rows, img_cols),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
        "\n",
        "print(len(train_generator), len(validation_generator))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "782 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Hd-bq1v0E0",
        "colab_type": "text"
      },
      "source": [
        "#### Number of conv blocks - 4, number of layers in each block - 4. \n",
        "#### There are 3 transition blocks. There are no dropout, dense layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtEpWGs5yh0j",
        "colab_type": "code",
        "outputId": "fa583db3-35fe-4c83-d7a8-7f86c697d36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Dropout\n",
        ")\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def _bn_relu(input):  \n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=3)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding, use_bias=False,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "  \n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding, use_bias=False,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "  \n",
        "def create_block(input, num_filters, num_layers):\n",
        "    temp = input\n",
        "    for i in range(num_layers):\n",
        "      input = _bn_relu_conv(filters=num_filters, kernel_size=(3, 3), strides=(1, 1))(input)\n",
        "      print(\"shape inside block \", input.shape)\n",
        "      num_filters *= 2    \n",
        "\n",
        "    block = concatenate([temp, input])\n",
        "    print(\"block shape after concat \", block.shape)\n",
        "    return block\n",
        "  \n",
        "  \n",
        "def create_transition(input):\n",
        "    one_conv = _bn_relu_conv(filters=150, kernel_size=(1, 1), strides=(1, 1))(input)\n",
        "    pool = MaxPooling2D(pool_size=(2, 2))(one_conv)\n",
        "    print(one_conv.shape, \"Inside transition\", pool.shape)\n",
        "    \n",
        "    return pool\n",
        "  \n",
        "  \n",
        "def output_layer(input):\n",
        "    output = _bn_relu_conv(filters=nb_classes, kernel_size=(1, 1), strides=(1, 1))(input)\n",
        "    output = MaxPooling2D(pool_size=(2, 2))(output)\n",
        "    \n",
        "    gap = GlobalAveragePooling2D()(output)  # in place of Convolution2D(10, 7)\n",
        "    print(output.shape, \" GAP \", gap.shape)\n",
        "    output = Activation('softmax')(gap)\n",
        "    print(\"Output \", output.shape)\n",
        "    return output  \n",
        "    \n",
        "    \n",
        "filters = 32\n",
        "layers_in_blk = 4\n",
        "\n",
        "input = Input(shape=(img_rows, img_cols, img_channels,))\n",
        "print(type(input), \" input shape \", input.shape)\n",
        "conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=(1, 1))(input)\n",
        "conv2 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=(1, 1))(conv1)\n",
        "conv3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3), strides=(1, 1))(conv2)\n",
        "print(\"conv3 shape \", conv3.shape)\n",
        "        \n",
        "block1 = create_block(conv3, filters, layers_in_blk)\n",
        "trans1 = create_transition(block1)\n",
        "\n",
        "block2 = create_block(trans1, filters, layers_in_blk)\n",
        "trans2 = create_transition(block2)\n",
        "\n",
        "block3 = create_block(trans2, filters, layers_in_blk)\n",
        "trans3 = create_transition(block3)\n",
        "\n",
        "block4 = create_block(trans3, filters, layers_in_blk)\n",
        "output = output_layer(block4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.Tensor'>  input shape  (?, 64, 64, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "conv3 shape  (?, 64, 64, 32)\n",
            "shape inside block  (?, 64, 64, 32)\n",
            "shape inside block  (?, 64, 64, 64)\n",
            "shape inside block  (?, 64, 64, 128)\n",
            "shape inside block  (?, 64, 64, 256)\n",
            "block shape after concat  (?, 64, 64, 288)\n",
            "(?, 64, 64, 150) Inside transition (?, 32, 32, 150)\n",
            "shape inside block  (?, 32, 32, 32)\n",
            "shape inside block  (?, 32, 32, 64)\n",
            "shape inside block  (?, 32, 32, 128)\n",
            "shape inside block  (?, 32, 32, 256)\n",
            "block shape after concat  (?, 32, 32, 406)\n",
            "(?, 32, 32, 150) Inside transition (?, 16, 16, 150)\n",
            "shape inside block  (?, 16, 16, 32)\n",
            "shape inside block  (?, 16, 16, 64)\n",
            "shape inside block  (?, 16, 16, 128)\n",
            "shape inside block  (?, 16, 16, 256)\n",
            "block shape after concat  (?, 16, 16, 406)\n",
            "(?, 16, 16, 150) Inside transition (?, 8, 8, 150)\n",
            "shape inside block  (?, 8, 8, 32)\n",
            "shape inside block  (?, 8, 8, 64)\n",
            "shape inside block  (?, 8, 8, 128)\n",
            "shape inside block  (?, 8, 8, 256)\n",
            "block shape after concat  (?, 8, 8, 406)\n",
            "(?, 4, 4, 200)  GAP  (?, 200)\n",
            "Output  (?, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3s2aYOqEJ30",
        "colab_type": "text"
      },
      "source": [
        "#### Parameters are 1.96m instead of 23.9m of Resnet50. Best validation accuracy ~ 48.68% at epoch 73 and training accuracy~63.2%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW0Y9xkuNt9I",
        "colab_type": "code",
        "outputId": "cabe6b54-8d05-40e8-f3d4-b9c069389d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3178
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 3)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 32)   864         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 32)   9216        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 32)   9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 32)   9216        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 64)   18432       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 128)  73728       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 256)  294912      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 288)  0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 288)  1152        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 288)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 150)  43200       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 150)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 150)  600         max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 150)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   43200       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 64)   18432       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  73728       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  294912      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 406)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 406)  1624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 406)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 150)  60900       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 150)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 150)  600         max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 150)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   43200       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   18432       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  73728       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 256)  294912      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 406)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 406)  1624        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 406)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 150)  60900       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 150)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 150)    600         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 150)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 32)     43200       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 32)     128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 32)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     18432       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 128)    73728       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 128)    512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 128)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 256)    294912      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8, 8, 406)    0           max_pooling2d_3[0][0]            \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 406)    1624        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 406)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 200)    81200       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 200)    0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,964,404\n",
            "Trainable params: 1,958,502\n",
            "Non-trainable params: 5,902\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmPOco3P7k9N",
        "colab_type": "code",
        "outputId": "6953ce69-ce62-44ec-b493-954a98142feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1144
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=2)\n",
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 0,\n",
        "                    epochs=20,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 899s 1s/step - loss: 5.1850 - acc: 0.0572 - val_loss: 5.6218 - val_acc: 0.0447\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 886s 1s/step - loss: 4.5335 - acc: 0.1179 - val_loss: 5.0299 - val_acc: 0.0887\n",
            "\n",
            "Epoch 00002: val_acc improved from -inf to 0.08870, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/002-0.0887.hdf5\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 883s 1s/step - loss: 4.1260 - acc: 0.1706 - val_loss: 4.6641 - val_acc: 0.1178\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 887s 1s/step - loss: 3.8295 - acc: 0.2182 - val_loss: 4.7761 - val_acc: 0.1363\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.08870 to 0.13630, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/004-0.1363.hdf5\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 886s 1s/step - loss: 3.6053 - acc: 0.2568 - val_loss: 4.1038 - val_acc: 0.1939\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 886s 1s/step - loss: 3.4521 - acc: 0.2853 - val_loss: 4.5096 - val_acc: 0.1653\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.13630 to 0.16530, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/006-0.1653.hdf5\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 884s 1s/step - loss: 3.3183 - acc: 0.3130 - val_loss: 3.5918 - val_acc: 0.2647\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 885s 1s/step - loss: 3.2460 - acc: 0.3295 - val_loss: 3.5496 - val_acc: 0.2900\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.16530 to 0.29000, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/008-0.2900.hdf5\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 885s 1s/step - loss: 3.1621 - acc: 0.3465 - val_loss: 4.1829 - val_acc: 0.2050\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 886s 1s/step - loss: 3.0938 - acc: 0.3613 - val_loss: 4.0331 - val_acc: 0.2435\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.29000\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 885s 1s/step - loss: 3.0359 - acc: 0.3734 - val_loss: 3.7441 - val_acc: 0.2796\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 882s 1s/step - loss: 2.9981 - acc: 0.3835 - val_loss: 3.9271 - val_acc: 0.2688\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.29000\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 880s 1s/step - loss: 2.9415 - acc: 0.3936 - val_loss: 3.6499 - val_acc: 0.2990\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 880s 1s/step - loss: 2.9074 - acc: 0.4040 - val_loss: 3.5621 - val_acc: 0.3019\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.29000 to 0.30190, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/014-0.3019.hdf5\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 879s 1s/step - loss: 2.8726 - acc: 0.4124 - val_loss: 3.9279 - val_acc: 0.2651\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 880s 1s/step - loss: 2.8450 - acc: 0.4185 - val_loss: 3.6919 - val_acc: 0.2937\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.30190\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 879s 1s/step - loss: 2.8150 - acc: 0.4255 - val_loss: 3.8037 - val_acc: 0.3087\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 879s 1s/step - loss: 2.7901 - acc: 0.4321 - val_loss: 3.4878 - val_acc: 0.3334\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.30190 to 0.33340, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/018-0.3334.hdf5\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 878s 1s/step - loss: 2.7644 - acc: 0.4360 - val_loss: 4.1780 - val_acc: 0.2644\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 878s 1s/step - loss: 2.7480 - acc: 0.4395 - val_loss: 3.9890 - val_acc: 0.2737\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.33340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f70680128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7kSnlXb9Ok2",
        "colab_type": "code",
        "outputId": "c8615f8a-6312-4d85-cff7-891c0b783c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.load_weights(dir + \"018-0.3334.hdf5\")\n",
        "print(\"Loaded model from disk\")\n",
        "model.evaluate_generator(generator=validation_generator, steps=len(validation_generator), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "79/79 [==============================] - 31s 390ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.4990049213409424, 0.3331]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnaBZpeUEnNP",
        "colab_type": "code",
        "outputId": "8cb486b6-eab0-435a-8477-14d8f2fb4e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=2)\n",
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 20,\n",
        "                    epochs=35,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 21/35\n",
            "782/782 [==============================] - 881s 1s/step - loss: 2.7872 - acc: 0.4312 - val_loss: 3.2504 - val_acc: 0.3588\n",
            "Epoch 22/35\n",
            "782/782 [==============================] - 862s 1s/step - loss: 2.7562 - acc: 0.4366 - val_loss: 3.3678 - val_acc: 0.3436\n",
            "\n",
            "Epoch 00022: val_acc improved from -inf to 0.34360, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/022-0.3436.hdf5\n",
            "Epoch 23/35\n",
            "782/782 [==============================] - 861s 1s/step - loss: 2.7337 - acc: 0.4420 - val_loss: 3.9522 - val_acc: 0.2849\n",
            "Epoch 24/35\n",
            "782/782 [==============================] - 861s 1s/step - loss: 2.7179 - acc: 0.4472 - val_loss: 3.2965 - val_acc: 0.3543\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.34360 to 0.35430, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/024-0.3543.hdf5\n",
            "Epoch 25/35\n",
            "782/782 [==============================] - 860s 1s/step - loss: 2.6974 - acc: 0.4491 - val_loss: 3.6999 - val_acc: 0.3109\n",
            "Epoch 26/35\n",
            "782/782 [==============================] - 859s 1s/step - loss: 2.6849 - acc: 0.4536 - val_loss: 3.7639 - val_acc: 0.3011\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.35430\n",
            "Epoch 27/35\n",
            "782/782 [==============================] - 859s 1s/step - loss: 2.4301 - acc: 0.5105 - val_loss: 3.0168 - val_acc: 0.4139\n",
            "Epoch 28/35\n",
            "782/782 [==============================] - 858s 1s/step - loss: 2.3535 - acc: 0.5221 - val_loss: 2.8545 - val_acc: 0.4367\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.35430 to 0.43670, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/028-0.4367.hdf5\n",
            "Epoch 29/35\n",
            "782/782 [==============================] - 859s 1s/step - loss: 2.3223 - acc: 0.5268 - val_loss: 2.8595 - val_acc: 0.4297\n",
            "Epoch 30/35\n",
            "782/782 [==============================] - 863s 1s/step - loss: 2.2937 - acc: 0.5293 - val_loss: 2.8466 - val_acc: 0.4343\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.43670\n",
            "Epoch 31/35\n",
            "782/782 [==============================] - 858s 1s/step - loss: 2.2658 - acc: 0.5331 - val_loss: 2.9275 - val_acc: 0.4253\n",
            "Epoch 32/35\n",
            "782/782 [==============================] - 858s 1s/step - loss: 2.2398 - acc: 0.5365 - val_loss: 3.0547 - val_acc: 0.4007\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.43670\n",
            "Epoch 33/35\n",
            "782/782 [==============================] - 858s 1s/step - loss: 2.2236 - acc: 0.5388 - val_loss: 2.7772 - val_acc: 0.4542\n",
            "Epoch 34/35\n",
            "782/782 [==============================] - 858s 1s/step - loss: 2.2084 - acc: 0.5415 - val_loss: 3.1147 - val_acc: 0.4016\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.43670\n",
            "Epoch 35/35\n",
            "782/782 [==============================] - 857s 1s/step - loss: 2.1886 - acc: 0.5456 - val_loss: 2.9723 - val_acc: 0.4192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f956577c320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-ssFSr5f-x2",
        "colab_type": "code",
        "outputId": "adcee680-f654-40be-8d78-53c196165198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(k.eval(model.optimizer.lr))\n",
        "model.load_weights(dir + \"028-0.4367.hdf5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "model.evaluate_generator(generator=validation_generator, steps=len(validation_generator), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001\n",
            "Loaded model from disk\n",
            "79/79 [==============================] - 27s 339ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.850449793624878, 0.4358]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucep8nSxhxdF",
        "colab_type": "code",
        "outputId": "c449a874-3ae8-45de-9f6e-5fbcfa6901be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1181
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=2)\n",
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 29,\n",
        "                    epochs=50,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "782/782 [==============================] - 856s 1s/step - loss: 2.6120 - acc: 0.4664 - val_loss: 3.5835 - val_acc: 0.3282\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 841s 1s/step - loss: 2.5869 - acc: 0.4725 - val_loss: 3.4580 - val_acc: 0.3365\n",
            "\n",
            "Epoch 00031: val_acc improved from -inf to 0.33650, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/031-0.3365.hdf5\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 841s 1s/step - loss: 2.5818 - acc: 0.4748 - val_loss: 3.9711 - val_acc: 0.2891\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 842s 1s/step - loss: 2.5771 - acc: 0.4788 - val_loss: 3.2829 - val_acc: 0.3637\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.33650 to 0.36370, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/033-0.3637.hdf5\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 841s 1s/step - loss: 2.5667 - acc: 0.4801 - val_loss: 3.9036 - val_acc: 0.3029\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 840s 1s/step - loss: 2.5624 - acc: 0.4817 - val_loss: 3.6897 - val_acc: 0.3215\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.36370\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 840s 1s/step - loss: 2.5843 - acc: 0.4787 - val_loss: 3.6524 - val_acc: 0.3244\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 841s 1s/step - loss: 2.5671 - acc: 0.4811 - val_loss: 3.2289 - val_acc: 0.3895\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.36370 to 0.38950, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/037-0.3895.hdf5\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 842s 1s/step - loss: 2.5763 - acc: 0.4812 - val_loss: 3.3328 - val_acc: 0.3578\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 841s 1s/step - loss: 2.5657 - acc: 0.4851 - val_loss: 3.3161 - val_acc: 0.3803\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.38950\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 844s 1s/step - loss: 2.5565 - acc: 0.4851 - val_loss: 3.4189 - val_acc: 0.3579\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 843s 1s/step - loss: 2.5439 - acc: 0.4888 - val_loss: 3.8268 - val_acc: 0.3039\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.38950\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 846s 1s/step - loss: 2.5399 - acc: 0.4893 - val_loss: 3.6847 - val_acc: 0.3344\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 842s 1s/step - loss: 2.2928 - acc: 0.5459 - val_loss: 3.0970 - val_acc: 0.4189\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.38950 to 0.41890, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/043-0.4189.hdf5\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 843s 1s/step - loss: 2.2233 - acc: 0.5562 - val_loss: 2.8878 - val_acc: 0.4464\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 846s 1s/step - loss: 2.1891 - acc: 0.5610 - val_loss: 3.2208 - val_acc: 0.4018\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.41890\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 847s 1s/step - loss: 2.1567 - acc: 0.5666 - val_loss: 3.0696 - val_acc: 0.4170\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 848s 1s/step - loss: 2.1383 - acc: 0.5669 - val_loss: 2.9594 - val_acc: 0.4327\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.41890 to 0.43270, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/047-0.4327.hdf5\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 846s 1s/step - loss: 2.1177 - acc: 0.5723 - val_loss: 3.0113 - val_acc: 0.4307\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 844s 1s/step - loss: 2.0990 - acc: 0.5739 - val_loss: 2.8983 - val_acc: 0.4362\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.43270 to 0.43620, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/049-0.4362.hdf5\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 843s 1s/step - loss: 1.9994 - acc: 0.5963 - val_loss: 2.7055 - val_acc: 0.4747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b286c2358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkaYb6W0yG5o",
        "colab_type": "code",
        "outputId": "0082cd33-96e2-46f2-ed9f-f5ec5c99641b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 50,\n",
        "                    epochs=60,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 51/60\n",
            "782/782 [==============================] - 844s 1s/step - loss: 1.9602 - acc: 0.6035 - val_loss: 2.7584 - val_acc: 0.4627\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.43620 to 0.46270, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/051-0.4627.hdf5\n",
            "Epoch 52/60\n",
            "782/782 [==============================] - 843s 1s/step - loss: 1.9496 - acc: 0.6054 - val_loss: 2.8058 - val_acc: 0.4594\n",
            "Epoch 53/60\n",
            "782/782 [==============================] - 847s 1s/step - loss: 1.9420 - acc: 0.6077 - val_loss: 2.6440 - val_acc: 0.4850\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.46270 to 0.48500, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/053-0.4850.hdf5\n",
            "Epoch 54/60\n",
            "782/782 [==============================] - 839s 1s/step - loss: 1.9312 - acc: 0.6068 - val_loss: 2.7363 - val_acc: 0.4675\n",
            "Epoch 55/60\n",
            "782/782 [==============================] - 838s 1s/step - loss: 1.9244 - acc: 0.6085 - val_loss: 2.6785 - val_acc: 0.4797\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.48500\n",
            "Epoch 56/60\n",
            "782/782 [==============================] - 837s 1s/step - loss: 1.9154 - acc: 0.6108 - val_loss: 2.8444 - val_acc: 0.4569\n",
            "Epoch 57/60\n",
            "782/782 [==============================] - 840s 1s/step - loss: 1.9032 - acc: 0.6138 - val_loss: 2.6663 - val_acc: 0.4785\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.48500\n",
            "Epoch 58/60\n",
            "782/782 [==============================] - 842s 1s/step - loss: 1.8960 - acc: 0.6137 - val_loss: 2.7896 - val_acc: 0.4629\n",
            "Epoch 59/60\n",
            "782/782 [==============================] - 839s 1s/step - loss: 1.8626 - acc: 0.6232 - val_loss: 2.7655 - val_acc: 0.4701\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.48500\n",
            "Epoch 60/60\n",
            "782/782 [==============================] - 843s 1s/step - loss: 1.8439 - acc: 0.6255 - val_loss: 2.6812 - val_acc: 0.4728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b271dc9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKM7urGHY_Lx",
        "colab_type": "code",
        "outputId": "489b6c4b-9904-433f-a444-e1de025acd60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 60,\n",
        "                    epochs=70,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 61/70\n",
            "782/782 [==============================] - 842s 1s/step - loss: 1.8375 - acc: 0.6277 - val_loss: 2.7443 - val_acc: 0.4678\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.48500\n",
            "Epoch 62/70\n",
            "782/782 [==============================] - 841s 1s/step - loss: 1.8401 - acc: 0.6267 - val_loss: 2.6826 - val_acc: 0.4781\n",
            "Epoch 63/70\n",
            "782/782 [==============================] - 837s 1s/step - loss: 1.8293 - acc: 0.6289 - val_loss: 2.6891 - val_acc: 0.4759\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.48500\n",
            "Epoch 64/70\n",
            "782/782 [==============================] - 840s 1s/step - loss: 1.8314 - acc: 0.6284 - val_loss: 2.6912 - val_acc: 0.4789\n",
            "Epoch 65/70\n",
            "782/782 [==============================] - 839s 1s/step - loss: 1.8277 - acc: 0.6287 - val_loss: 2.7453 - val_acc: 0.4713\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.48500\n",
            "Epoch 66/70\n",
            "782/782 [==============================] - 845s 1s/step - loss: 1.8203 - acc: 0.6298 - val_loss: 2.6783 - val_acc: 0.4774\n",
            "Epoch 67/70\n",
            "782/782 [==============================] - 847s 1s/step - loss: 1.8198 - acc: 0.6293 - val_loss: 2.6648 - val_acc: 0.4805\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.48500\n",
            "Epoch 68/70\n",
            "782/782 [==============================] - 846s 1s/step - loss: 1.8202 - acc: 0.6283 - val_loss: 2.6645 - val_acc: 0.4830\n",
            "Epoch 69/70\n",
            "782/782 [==============================] - 846s 1s/step - loss: 1.8151 - acc: 0.6284 - val_loss: 2.6669 - val_acc: 0.4805\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.48500\n",
            "Epoch 70/70\n",
            "782/782 [==============================] - 846s 1s/step - loss: 1.8049 - acc: 0.6331 - val_loss: 2.6349 - val_acc: 0.4847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b27518da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hq2KriU59h9",
        "colab_type": "code",
        "outputId": "b3cd9628-4972-44d1-ad64-a96410682dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 70,\n",
        "                    epochs=80,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 71/80\n",
            "782/782 [==============================] - 851s 1s/step - loss: 1.8128 - acc: 0.6303 - val_loss: 2.6793 - val_acc: 0.4830\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.48500\n",
            "Epoch 72/80\n",
            "782/782 [==============================] - 846s 1s/step - loss: 1.7994 - acc: 0.6343 - val_loss: 2.6768 - val_acc: 0.4775\n",
            "Epoch 73/80\n",
            "782/782 [==============================] - 846s 1s/step - loss: 1.8075 - acc: 0.6324 - val_loss: 2.6192 - val_acc: 0.4868\n",
            "\n",
            "Epoch 00073: val_acc improved from 0.48500 to 0.48680, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/073-0.4868.hdf5\n",
            "Epoch 74/80\n",
            "782/782 [==============================] - 847s 1s/step - loss: 1.8039 - acc: 0.6312 - val_loss: 2.6532 - val_acc: 0.4813\n",
            "Epoch 75/80\n",
            "782/782 [==============================] - 847s 1s/step - loss: 1.7955 - acc: 0.6326 - val_loss: 2.6444 - val_acc: 0.4819\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.48680\n",
            "Epoch 76/80\n",
            " 27/782 [>.............................] - ETA: 13:13 - loss: 1.7495 - acc: 0.6522"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQNT9Xk1lRBr",
        "colab_type": "code",
        "outputId": "ef103371-1695-492a-88eb-48098a8be264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "model.load_weights(dir + \"073-0.4868.hdf5\")\n",
        "print(\"Loaded model from disk\")\n",
        "print(k.eval(model.optimizer.lr))\n",
        "\n",
        "print(k.eval(model.optimizer.lr))\n",
        "model.evaluate_generator(generator=validation_generator, steps=len(validation_generator), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "0.001\n",
            "79/79 [==============================] - 26s 330ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6386054050445558, 0.4827]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpR-6-AEmgIE",
        "colab_type": "code",
        "outputId": "735ff516-2197-4637-9443-a3656d40d2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=.000031622778),\n",
        "              metrics=['accuracy'])\n",
        "model.load_weights(dir + \"073-0.4868.hdf5\")\n",
        "print(\"Loaded model from disk\")\n",
        "print(\"Optimiser init with lr \", k.eval(model.optimizer.lr))\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=2)\n",
        "model.fit_generator(train_generator, steps_per_epoch=len(train_generator),                     \n",
        "                    validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                    verbose=1,\n",
        "                    initial_epoch = 74,\n",
        "                    epochs=84,\n",
        "                    max_queue_size=100,\n",
        "                    callbacks=[checkpoint, lr_reducer, early_stopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "Optimiser init with lr  3.1622778e-05\n",
            "Epoch 75/84\n",
            "782/782 [==============================] - 875s 1s/step - loss: 1.7899 - acc: 0.6364 - val_loss: 2.6738 - val_acc: 0.4780\n",
            "Epoch 76/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7811 - acc: 0.6374 - val_loss: 2.6637 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00076: val_acc improved from -inf to 0.48110, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/076-0.4811.hdf5\n",
            "Epoch 77/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7718 - acc: 0.6411 - val_loss: 2.7121 - val_acc: 0.4732\n",
            "Epoch 78/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7724 - acc: 0.6394 - val_loss: 2.7852 - val_acc: 0.4661\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.48110\n",
            "Epoch 79/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7625 - acc: 0.6401 - val_loss: 2.6414 - val_acc: 0.4854\n",
            "Epoch 80/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7601 - acc: 0.6421 - val_loss: 2.6558 - val_acc: 0.4812\n",
            "\n",
            "Epoch 00080: val_acc improved from 0.48110 to 0.48120, saving model to /content/gdrive/My Drive/Colab Notebooks/Assignment4/CustomWts_2c/080-0.4812.hdf5\n",
            "Epoch 81/84\n",
            "782/782 [==============================] - 861s 1s/step - loss: 1.7572 - acc: 0.6420 - val_loss: 2.7009 - val_acc: 0.4766\n",
            "Epoch 82/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7481 - acc: 0.6453 - val_loss: 2.6700 - val_acc: 0.4773\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.48120\n",
            "Epoch 83/84\n",
            "782/782 [==============================] - 860s 1s/step - loss: 1.7527 - acc: 0.6428 - val_loss: 2.6825 - val_acc: 0.4783\n",
            "Epoch 84/84\n",
            "782/782 [==============================] - 859s 1s/step - loss: 1.7403 - acc: 0.6465 - val_loss: 2.6816 - val_acc: 0.4745\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.48120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89880b9f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfl0MIbkZDFD",
        "colab_type": "code",
        "outputId": "8c5f8065-2200-46c2-b6b3-c7a792037103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.load_weights(dir + \"073-0.4868.hdf5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=.000010000001),\n",
        "              metrics=['accuracy'])\n",
        "print(\"Optimiser init with lr \", k.eval(model.optimizer.lr))\n",
        "model.evaluate_generator(generator=validation_generator, steps=len(validation_generator), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "Optimiser init with lr  1.0000001e-05\n",
            "79/79 [==============================] - 27s 342ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.638605305099487, 0.4827]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG9EneODqQN3",
        "colab_type": "text"
      },
      "source": [
        "At this point, **model is saturated** with training accuracy ~ 63.2% and validation accuracy ~ 48.68 at epoch 73. After this, train accuracy rises only slightly to 64.6%, but validation accuracy starts reducing.\n",
        "\n",
        "Now, classes which have bad accuracy needs to be identified. And write a generator which trains these hard images from bad classes in more numbers."
      ]
    }
  ]
}